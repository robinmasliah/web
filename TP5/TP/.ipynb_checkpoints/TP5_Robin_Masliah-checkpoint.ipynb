{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robin MASLIAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv as csv\n",
    "import nltk as nltk\n",
    "import re\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sentiwordnet import SentiWordNetCorpusReader, SentiSynset\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./csvTweetData.csv', sep=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns = ['polarity', 'id', 'date', 'query', 'user', 'tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity  id                          date    query      user  \\\n",
       "0         4   3  Mon May 11 03:17:40 UTC 2009  kindle2    tpryan   \n",
       "1         4   4  Mon May 11 03:18:03 UTC 2009  kindle2    vcu451   \n",
       "2         4   5  Mon May 11 03:18:54 UTC 2009  kindle2    chadfu   \n",
       "3         4   6  Mon May 11 03:19:04 UTC 2009  kindle2     SIX15   \n",
       "4         4   7  Mon May 11 03:21:41 UTC 2009  kindle2  yamarama   \n",
       "\n",
       "                                               tweet  \n",
       "0  @stellargirl I loooooooovvvvvveee my Kindle2. ...  \n",
       "1  Reading my kindle2...  Love it... Lee childs i...  \n",
       "2  Ok, first assesment of the #kindle2 ...it fuck...  \n",
       "3  @kenburbary You'll love your Kindle2. I've had...  \n",
       "4  @mikefish  Fair enough. But i have the Kindle2...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√©traitements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cleaning functions\n",
    "def remove_hashtags(sentence):\n",
    "    return re.sub('#', '', sentence)\n",
    "\n",
    "def remove_links(sentence):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", sentence).split())\n",
    "\n",
    "def remove_dots(sentence):\n",
    "    return sentence.replace('.', ' ')\n",
    "\n",
    "def split_it(sentence):\n",
    "    return re.findall('([^\\s]+)', sentence)\n",
    "\n",
    "def remove_openpar(sentence):\n",
    "    return re.sub('(', '', sentence)\n",
    "\n",
    "def clean(sentence):\n",
    "    sentence = sentence.strip(\"#\")\n",
    "    if re.search('[a-zA-Z]', sentence):\n",
    "        sentence = sentence.strip(\".:,;_-!?[](){}*$\\\"\")\n",
    "        sentence = sentence.replace(\".\",\" \")\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda x: remove_links(x))\n",
    "df['tweet'] = df['tweet'].apply(lambda x: remove_hashtags(x))\n",
    "df['tweet'] = df['tweet'].apply(lambda x: remove_dots(x))\n",
    "df['tweet'] = df['tweet'].apply(lambda x: split_it(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in df['tweet'].index:\n",
    "    for index, j in enumerate(df['tweet'][i]):\n",
    "        df['tweet'][i][index] = clean(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['I', 'loooooooovvvvvveee', 'my', 'Kindle2', 'Not', 'that', 'the', 'DX', 'is', 'cool', 'but', 'the', '2', 'is', 'fantastic', 'in', 'its', 'own', 'right']),\n",
       "       list(['Reading', 'my', 'kindle2', 'Love', 'it', 'Lee', 'childs', 'is', 'good', 'read']),\n",
       "       list(['Ok', 'first', 'assesment', 'of', 'the', 'kindle2', 'it', 'fucking', 'rocks']),\n",
       "       list([\"You'll\", 'love', 'your', 'Kindle2', \"I've\", 'had', 'mine', 'for', 'a', 'few', 'months', 'and', 'never', 'looked', 'back', 'The', 'new', 'big', 'one', 'is', 'huge', 'No', 'need', 'for', 'remorse', ':)']),\n",
       "       list(['Fair', 'enough', 'But', 'i', 'have', 'the', 'Kindle2', 'and', 'I', 'think', \"it's\", 'perfect', ':)']),\n",
       "       list(['no', 'it', 'is', 'too', 'big', \"I'm\", 'quite', 'happy', 'with', 'the', 'Kindle2']),\n",
       "       list(['Fuck', 'this', 'economy', 'I', 'hate', 'aig', 'and', 'their', 'non', 'loan', 'given', 'asses']),\n",
       "       list(['Jquery', 'is', 'my', 'new', 'best', 'friend']),\n",
       "       list(['Loves', 'twitter']),\n",
       "       list(['how', 'can', 'you', 'not', 'love', 'Obama', 'he', 'makes', 'jokes', 'about', 'himself']),\n",
       "       list(['Check', 'this', 'video', 'out', '--', 'President', 'Obama', 'at', 'the', 'White', 'House', \"Correspondents'\", 'Dinner']),\n",
       "       list(['I', 'firmly', 'believe', 'that', 'Obama/Pelosi', 'have', 'ZERO', 'desire', 'to', 'be', 'civil', \"It's\", 'a', 'charade', 'and', 'a', 'slogan', 'but', 'they', 'want', 'to', 'destroy', 'conservatism']),\n",
       "       list(['House', 'Correspondents', 'dinner', 'was', 'last', 'night', 'whoopi', 'barbara', '&amp', 'sherri', 'went', 'Obama', 'got', 'a', 'standing', 'ovation']),\n",
       "       list(['Watchin', 'Espn', 'Jus', 'seen', 'this', 'new', 'Nike', 'Commerical', 'with', 'a', 'Puppet', 'Lebron', 'sh*t', 'was', 'hilarious', 'LMAO']),\n",
       "       list(['dear', 'nike', 'stop', 'with', 'the', 'flywire', 'that', 'shit', 'is', 'a', 'waste', 'of', 'science', 'and', 'ugly', 'love']),\n",
       "       list(['lebron', 'best', 'athlete', 'of', 'our', 'generation', 'if', 'not', 'all', 'time', 'basketball', 'related', 'I', \"don't\", 'want', 'to', 'get', 'into', 'inter-sport', 'debates', 'about', '__1/2']),\n",
       "       list(['I', 'was', 'talking', 'to', 'this', 'guy', 'last', 'night', 'and', 'he', 'was', 'telling', 'me', 'that', 'he', 'is', 'a', 'die', 'hard', 'Spurs', 'fan', 'He', 'also', 'told', 'me', 'that', 'he', 'hates', 'LeBron', 'James']),\n",
       "       list(['i', 'love', 'lebron']),\n",
       "       list(['Lebron', 'is', 'a', 'Beast', 'but', \"I'm\", 'still', 'cheering', '4', 'the', 'A', 'til', 'the', 'end']),\n",
       "       list(['lebron', 'IS', 'THE', 'BOSS']),\n",
       "       list(['Lebron', 'is', 'a', 'hometown', 'hero', 'to', 'me', 'lol', 'I', 'love', 'the', 'Lakers', 'but', \"let's\", 'go', 'Cavs', 'lol']),\n",
       "       list(['lebron', 'and', 'zydrunas', 'are', 'such', 'an', 'awesome', 'duo']),\n",
       "       list(['Lebron', 'is', 'a', 'beast', 'nobody', 'in', 'the', 'NBA', 'comes', 'even', 'close']),\n",
       "       list(['downloading', 'apps', 'for', 'my', 'iphone', 'So', 'much', 'fun', ':-)', 'There', 'literally', 'is', 'an', 'app', 'for', 'just', 'about', 'anything']),\n",
       "       list(['good', 'news', 'just', 'had', 'a', 'call', 'from', 'the', 'Visa', 'office', 'saying', 'everything', 'is', 'fine', 'what', 'a', 'relief', 'I', 'am', 'sick', 'of', 'scams', 'out', 'there', 'Stealing']),\n",
       "       list(['-', 'awesome', 'come', 'back', 'from', 'via', ')']),\n",
       "       list(['In', 'montreal', 'for', 'a', 'long', 'weekend', 'of', 'R&amp;R', 'Much', 'needed']),\n",
       "       list(['Booz', 'Allen', 'Hamilton', 'has', 'a', 'bad', 'ass', 'homegrown', 'social', 'collaboration', 'platform', 'Way', 'cool', 'ttiv']),\n",
       "       list(['MLUC09', 'Customer', 'Innovation', 'Award', 'Winner', 'Booz', 'Allen', 'Hamilton', '--']),\n",
       "       list(['I', 'current', 'use', 'the', 'Nikon', 'D90', 'and', 'love', 'it', 'but', 'not', 'as', 'much', 'as', 'the', 'Canon', '40D/50D', 'I', 'chose', 'the', 'D90', 'for', 'the', 'video', 'feature', 'My', 'mistake']),\n",
       "       list(['need', 'suggestions', 'for', 'a', 'good', 'IR', 'filter', 'for', 'my', 'canon', '40D', 'got', 'some', 'pls', 'DM']),\n",
       "       list([':', 'I', 'just', 'checked', 'my', 'google', 'for', 'my', 'business', 'blip', 'shows', 'up', 'as', 'the', 'second', 'entry', 'Huh', 'Is', 'that', 'a', 'good', 'or', 'ba', '?']),\n",
       "       list(['Google', 'is', 'always', 'a', 'good', 'place', 'to', 'look', \"Should've\", 'mentioned', 'I', 'worked', 'on', 'the', 'Mustang', 'w/', 'my', 'Dad']),\n",
       "       list(['Played', 'with', 'an', 'android', 'google', 'phone', 'The', 'slide', 'out', 'screen', 'scares', 'me', 'I', 'would', 'break', 'that', 'fucker', 'so', 'fast', 'Still', 'prefer', 'my', 'iPhone']),\n",
       "       list(['US', 'planning', 'to', 'resume', 'the', 'military', 'tribunals', 'at', 'Guantanamo', 'Bay', 'only', 'this', 'time', 'those', 'on', 'trial', 'will', 'be', 'AIG', 'execs', 'and', 'Chrysler', 'debt', 'holders']),\n",
       "       list(['omg', 'so', 'bored', '&amp', 'my', 'tattoooos', 'are', 'so', 'itchy', 'help', 'aha', '=)']),\n",
       "       list([\"I'm\", 'itchy', 'and', 'miserable']),\n",
       "       list(['no', \"I'm\", 'not', 'itchy', 'for', 'now', 'Maybe', 'later', 'lol']),\n",
       "       list(['RT', 'I', 'love', 'the', 'nerdy', 'Stanford', 'human', 'biology', 'videos', '-', 'makes', 'me', 'miss', 'school']),\n",
       "       list([':', 'Has', 'been', 'a', 'bit', 'crazy', 'with', 'steep', 'learning', 'curve', 'but', 'LyX', 'is', 'really', 'good', 'for', 'long', 'docs', 'For', 'anything', 'shorter', 'it', 'would', 'be', 'insane']),\n",
       "       list([\"I'm\", 'listening', 'to', 'P', 'Y', 'T', 'by', 'Danny', 'Gokey', '&lt;3', '&lt;3', '&lt;3', 'Aww', \"he's\", 'so', 'amazing', 'I', '&lt;3', 'him', 'so', 'much', ':)']),\n",
       "       list(['is', 'going', 'to', 'sleep', 'then', 'on', 'a', 'bike', 'ride']),\n",
       "       list(['cant', 'sleep', 'my', 'tooth', 'is', 'aching']),\n",
       "       list(['Blah', 'blah', 'blah', 'same', 'old', 'same', 'old', 'No', 'plans', 'today', 'going', 'back', 'to', 'sleep', 'I', 'guess']),\n",
       "       list(['glad', 'i', 'didnt', 'do', 'Bay', 'to', 'Breakers', 'today', \"it's\", '1000', 'freaking', 'degrees', 'in', 'San', 'Francisco', 'wtf']),\n",
       "       list(['is', 'in', 'San', 'Francisco', 'at', 'Bay', 'to', 'Breakers']),\n",
       "       list(['just', 'landed', 'at', 'San', 'Francisco']),\n",
       "       list(['San', 'Francisco', 'today', 'Any', 'suggestions']),\n",
       "       list(['Obama', 'Administration', 'Must', 'Stop', 'Bonuses', 'to', 'AIG', 'Ponzi', 'Schemers']),\n",
       "       list(['started', 'to', 'think', 'that', 'Citi', 'is', 'in', 'really', 'deep', 's&amp;^t', 'Are', 'they', 'gonna', 'survive', 'the', 'turmoil', 'or', 'are', 'they', 'gonna', 'be', 'the', 'next', 'AIG']),\n",
       "       list(['ShaunWoo', \"hate'n\", 'on', 'AiG']),\n",
       "       list(['you', 'will', 'not', 'regret', 'going', 'to', 'see', 'Star', 'Trek', 'It', 'was', 'AWESOME']),\n",
       "       list(['On', 'my', 'way', 'to', 'see', 'Star', 'Trek', '@', 'The', 'Esquire']),\n",
       "       list(['Going', 'to', 'see', 'star', 'trek', 'soon', 'with', 'my', 'dad']),\n",
       "       list(['annoying', 'new', 'trend', 'on', 'the', 'internets', 'people', 'picking', 'apart', 'michael', 'lewis', 'and', 'malcolm', 'gladwell', 'nobody', 'wants', 'to', 'read', 'that']),\n",
       "       list(['Bill', 'Simmons', 'in', 'conversation', 'with', 'Malcolm', 'Gladwell']),\n",
       "       list(['Highly', 'recommend', 'by', 'Malcolm', 'Gladwell']),\n",
       "       list(['Blink', 'by', 'malcolm', 'gladwell', 'amazing', 'book', 'and', 'The', 'tipping', 'point']),\n",
       "       list(['Malcolm', 'Gladwell', 'might', 'be', 'my', 'new', 'man', 'crush']),\n",
       "       list(['omg', 'The', 'commercials', 'alone', 'on', 'ESPN', 'are', 'going', 'to', 'drive', 'me', 'nuts']),\n",
       "       list(['Playing', 'with', 'Twitter', 'API', 'sounds', 'fun', 'May', 'need', 'to', 'take', 'a', 'class', 'or', 'find', 'a', 'new', 'friend', 'who', 'like', 'to', 'generate', 'results', 'with', 'API', 'code']),\n",
       "       list(['playing', 'with', 'cURL', 'and', 'the', 'Twitter', 'API']),\n",
       "       list(['Hello', 'Twitter', 'API', ';)']),\n",
       "       list(['playing', 'with', 'Java', 'and', 'the', 'Twitter', 'API']),\n",
       "       list(['Because', 'the', 'twitter', 'api', 'is', 'slow', 'and', 'most', \"client's\", \"aren't\", 'good']),\n",
       "       list(['yahoo', 'answers', 'can', 'be', 'a', 'butt', 'sometimes']),\n",
       "       list(['is', 'scrapbooking', 'with', 'Nic', '=D']),\n",
       "       list(['RT', ':', 'Five', 'Things', 'Wolfram', 'Alpha', 'Does', 'Better', 'And', 'Vastly', 'Different', 'Than', 'Google', '-']),\n",
       "       list(['just', 'changed', 'my', 'default', 'pic', 'to', 'a', 'Nike', 'basketball', 'cause', 'bball', 'is', 'awesome']),\n",
       "       list(['Nike', 'owns', 'NBA', 'Playoffs', 'ads', 'w/', 'LeBron', 'Kobe', 'Carmelo', 'Adidas', 'Billups', 'Howard', 'Marketing', 'Branding']),\n",
       "       list([\"'Next\", 'time', \"I'll\", 'call', 'myself', \"Nike'\"]),\n",
       "       list(['New', 'blog', 'post', 'Nike', 'SB', 'Dunk', 'Low', 'Premium', \"'White\", \"Gum'\"]),\n",
       "       list(['RT', ':', 'Was', 'just', 'told', 'that', 'Nike', 'layoffs', 'started', 'today', ':-(']),\n",
       "       list(['Back', 'when', 'I', 'worked', 'for', 'Nike', 'we', 'had', 'one', 'fav', 'word', ':', 'JUST', 'DO', 'IT', ':)']),\n",
       "       list(['By', 'the', 'way', \"I'm\", 'totally', 'inspired', 'by', 'this', 'freaky', 'Nike', 'commercial']),\n",
       "       list(['giving', 'weka', 'an', 'app', 'engine', 'interface', 'using', 'the', 'bird', 'strike', 'data', 'for', 'the', 'tests', 'the', 'logo', 'is', 'a', 'given']),\n",
       "       list(['Brand', 'New', 'Canon', 'EOS', '50D', '15MP', 'DSLR', 'Camera', 'Canon', '17-85mm', 'IS', 'Lens', ':', 'Web', 'Technology', 'Thread', 'Brand', 'New', 'Canon', 'EOS', '5']),\n",
       "       list(['Class', 'The', '50d', 'is', 'supposed', 'to', 'come', 'today', ':)']),\n",
       "       list(['needs', 'someone', 'to', 'explain', 'lambda', 'calculus', 'to', 'him', ':(']),\n",
       "       list(['Took', 'the', 'Graduate', 'Field', 'Exam', 'for', 'Computer', 'Science', 'today', 'Nothing', 'makes', 'you', 'feel', 'like', 'more', 'of', 'an', 'idiot', 'than', 'lambda', 'calculus']),\n",
       "       list(['SHOUT', 'OUTS', 'TO', 'ALL', 'EAST', 'PALO', 'ALTO', 'FOR', 'BEING', 'IN', 'THE', 'BUILDIN', 'KARIZMAKAZE', '50CAL', 'GTA', 'ALSO', 'THANKS', 'TO', 'PROFITS', 'OF', 'DOOM', 'UNIVERSAL', 'HEMPZ', 'CRACKA']),\n",
       "       list(['Yeahhhhhhhhh', 'I', \"wouldn't\", 'really', 'have', 'lived', 'in', 'East', 'Palo', 'Alto', 'if', 'I', 'could', 'have', 'avoided', 'it', 'I', 'guess', \"it's\", 'only', 'for', 'the', 'summer']),\n",
       "       list(['Great', 'Stanford', 'course', 'Thanks', 'for', 'making', 'it', 'available', 'to', 'the', 'public', 'Really', 'helpful', 'and', 'informative', 'for', 'starting', 'off']),\n",
       "       list(['NVIDIA', 'Names', \"Stanford's\", 'Bill', 'Dally', 'Chief', 'Scientist', 'VP', 'Of', 'Research']),\n",
       "       list(['New', 'blog', 'post', 'Harvard', 'Versus', 'Stanford', '-', 'Who', 'Wins']),\n",
       "       list(['@', 'work', 'til', '6pm', 'lets', 'go', 'lakers']),\n",
       "       list(['Damn', 'you', 'North', 'Korea']),\n",
       "       list(['Can', 'we', 'just', 'go', 'ahead', 'and', 'blow', 'North', 'Korea', 'off', 'the', 'map', 'already']),\n",
       "       list(['North', 'Korea', 'please', 'cease', 'this', 'douchebaggery', 'China', \"doesn't\", 'even', 'like', 'you', 'anymore']),\n",
       "       list(['Why', 'the', 'hell', 'is', 'Pelosi', 'in', 'freakin', 'China', 'and', 'on', 'whose', 'dime']),\n",
       "       list(['Are', 'YOU', 'burning', 'more', 'cash', '$$$', 'than', 'Chrysler', 'and', 'GM', 'Stop', 'the', 'financial', 'tsunami', 'Where', 'bailout', 'means', 'taking', 'a', 'handout']),\n",
       "       list(['insects', 'have', 'infected', 'my', 'spinach', 'plant', ':(']),\n",
       "       list(['wish', 'i', 'could', 'catch', 'every', 'mosquito', 'in', 'the', 'world', 'n', 'burn', 'em', 'slowly', 'they', 'been', 'bitin', 'the', 'shit', 'outta', 'me', '2day', 'mosquitos', 'are', 'the', 'assholes', 'of', 'insects']),\n",
       "       list(['just', 'got', 'back', 'from', 'church', 'and', 'I', 'totally', 'hate', 'insects']),\n",
       "       list(['Just', 'got', 'mcdonalds', 'goddam', 'those', 'eggs', 'make', 'me', 'sick', 'O', 'yeah', 'Laker', 'up', 'date', 'go', 'lakers', 'Not', 'much', 'of', 'an', 'update', 'Well', \"it's\", 'true', 'so', 'suck', 'it']),\n",
       "       list(['omgg', 'i', 'ohhdee', 'want', 'mcdonalds', 'damn', 'i', 'wonder', 'if', 'its', 'open', 'lol', '=]']),\n",
       "       list(['History', 'exam', 'studying', 'ugh']),\n",
       "       list(['I', 'hate', 'revision', \"it's\", 'so', 'boring', 'I', 'am', 'totally', 'unprepared', 'for', 'my', 'exam', 'tomorrow', ':(', 'Things', 'are', 'not', 'looking', 'good']),\n",
       "       list(['Higher', 'physics', 'exam', 'tommorow', 'not', 'lookin', 'forward', 'to', 'it', 'much', ':(']),\n",
       "       list([\"It's\", 'a', 'bank', 'holiday', 'yet', \"I'm\", 'only', 'out', 'of', 'work', 'now', 'Exam', 'season', 'sucks']),\n",
       "       list(['Cheney', 'and', 'Bush', 'are', 'the', 'real', 'culprits', '-']),\n",
       "       list(['Life?s', 'a', 'bitch', 'and', 'so', 'is', 'Dick', 'Cheney', 'p2', 'bipart', 'tlot', 'tcot', 'hhrs', 'GOP', 'DNC']),\n",
       "       list(['Dick', \"Cheney's\", 'dishonest', 'speech', 'about', 'torture', 'terror', 'and', 'Obama', 'Fred', 'Kaplan', 'Slate']),\n",
       "       list(['The', 'Republican', 'party', 'is', 'a', 'bunch', 'of', 'anti-abortion', 'zealots', 'who', \"couldn't\", 'draw', 'flies', 'to', 'a', 'dump', '\"', '--', 'Neal', 'Boortz', 'just', 'now', 'on', 'the', 'radio']),\n",
       "       list(['is', \"Twitter's\", 'connections', 'API', 'broken', 'Some', 'tweets', \"didn't\", 'make', 'it', 'to', 'Twitter']),\n",
       "       list(['i', 'srsly', 'hate', 'the', 'stupid', 'twitter', 'API', 'timeout', 'thing', 'soooo', 'annoying', ':(']),\n",
       "       list(['I', 'really', 'liked', \"'s\", 'Learning', 'jQuery', 'book', 'is', 'worth', 'a', 'look', 'too']),\n",
       "       list(['jQuery', 'UI', '1', '6', 'Book', 'Review', '-']),\n",
       "       list(['Very', 'Interesting', 'Ad', 'from', 'Adobe', 'by', 'Goodby', 'Silverstein', '&amp', 'Partners', '-', 'YouTube', '-', 'Adobe', 'CS4', 'Le', 'Sens', 'Propre']),\n",
       "       list(['Goodby', 'Silverstein', 'agency', 'new', 'site', 'Great']),\n",
       "       list(['RT', 'Goodby', \"Silverstein's\", 'new', 'site', 'I', 'enjoy', 'it', 'nice', 'find']),\n",
       "       list(['The', 'ever', 'amazing', 'Psyop', 'and', 'Goodby', 'Silverstein', '&amp', 'Partners', 'for', 'HP', 'Have', 'to', 'go', 'play', 'with', 'After', 'Effects', 'now']),\n",
       "       list(['top', 'ten', 'most', 'watched', 'on', 'Viral-Video', 'Chart', 'Love', 'the', 'nike', 'mostvaluablepuppets', 'campaign', 'from', 'Wieden', '&amp', 'Kennedy']),\n",
       "       list(['zomg', 'I', 'have', 'a', 'G2']),\n",
       "       list(['Ok', 'so', 'lots', 'of', 'buzz', 'from', 'IO2009', 'but', 'how', 'lucky', 'are', 'they', '-', 'a', 'Free', 'G2']),\n",
       "       list(['just', 'got', 'a', 'free', 'G2', 'android', 'at', 'google', 'i/o']),\n",
       "       list(['Guess', \"I'll\", 'be', 'retiring', 'my', 'G1', 'and', 'start', 'using', 'my', 'developer', 'G2', 'woot', 'googleio']),\n",
       "       list(['At', 'GWT', 'fireside', 'chat']),\n",
       "       list(['I', 'am', 'happy', 'for', 'Philip', 'being', 'at', 'GoogleIO', 'today']),\n",
       "       list(['Lakers', 'played', 'great', 'Cannot', 'wait', 'for', 'Thursday', 'night', 'Lakers', 'vs', '???']),\n",
       "       list(['Hi', 'there', 'does', 'anyone', 'have', 'a', 'great', 'source', 'for', 'advice', 'on', 'viral', 'marketing']),\n",
       "       list(['Judd', 'Apatow', 'creates', 'fake', 'sitcom', 'on', 'NBC', 'com', 'to', 'market', 'his', 'new', 'movie', 'viral', 'marketing', 'at', 'its', 'best']),\n",
       "       list([\"Here's\", 'A', 'case', 'study', 'on', 'how', 'to', 'use', 'viral', 'marketing', 'to', 'add', 'over', '10,000', 'people', 'to', 'your', 'list']),\n",
       "       list(['VIRAL', 'MARKETING', 'FAIL', 'This', 'Acia', 'Pills', 'brand', 'oughta', 'get', 'shut', 'down', 'for', 'hacking', 'into', \"people's\", \"messenger's\", 'i', 'get', '5-6', 'msgs', 'in', 'a', 'day', 'Arrrgh']),\n",
       "       list(['watching', 'Night', 'at', 'The', 'Museum', 'Lmao']),\n",
       "       list(['i', 'loved', 'night', 'at', 'the', 'museum']),\n",
       "       list(['going', 'to', 'see', 'the', 'new', 'night', 'at', 'the', 'museum', 'movie', 'with', 'my', 'family', 'oh', 'boy', 'a', 'three', 'year', 'old', 'in', 'the', 'movies', 'fuin']),\n",
       "       list(['just', 'got', 'back', 'from', 'the', 'movies', 'went', 'to', 'see', 'the', 'new', 'night', 'at', 'the', 'museum', 'with', 'rachel', 'it', 'was', 'good']),\n",
       "       list(['Just', 'saw', 'the', 'new', 'Night', 'at', 'the', 'Museum', 'movie', 'it', 'was', 'okay', 'lol', '7\\\\10']),\n",
       "       list(['Going', 'to', 'see', 'night', 'at', 'the', 'museum', '2', 'with', 'tall', 'boy']),\n",
       "       list(['I', 'will', 'take', 'you', 'on', 'a', 'date', 'to', 'see', 'night', 'at', 'the', 'museum', '2', 'whenever', 'you', 'want', 'it', 'looks', 'soooooo', 'good']),\n",
       "       list(['no', 'watching', 'The', 'Night', 'At', 'The', 'Museum', 'Getting', 'Really', 'Good']),\n",
       "       list(['Night', 'at', 'the', 'Museum', 'Wolverine', 'and', 'junk', 'food', '-', 'perfect', 'monday']),\n",
       "       list(['saw', 'night', 'at', 'the', 'museum', '2', 'last', 'night', 'pretty', 'crazy', 'movie', 'but', 'the', 'cast', 'was', 'awesome', 'so', 'it', 'was', 'well', 'worth', 'it', 'Robin', 'Williams', 'forever']),\n",
       "       list(['I', 'saw', 'Night', 'at', 'the', 'Museum', 'Battle', 'of', 'the', 'Swithsonian', 'today', 'It', 'was', 'okay', 'Your', 'typical', 'kids', 'Ben', 'Stiller', 'movie']),\n",
       "       list(['Taking', 'Katie', 'to', 'see', 'Night', 'at', 'the', 'Museum', 'she', 'picked', 'it']),\n",
       "       list(['Night', 'at', 'the', 'Museum', 'tonite', 'instead', 'of', 'UP', ':(', 'oh', 'well', 'that', '4', 'yr', 'old', 'better', 'enjoy', 'it', 'LOL']),\n",
       "       list(['GM', 'says', 'expects', 'announcment', 'on', 'sale', 'of', 'Hummer', 'soon', '-', 'Reuters', 'WDSUGM', 'says', 'expects', 'announcment', 'on', 'sale', 'of', 'Hummer']),\n",
       "       list([\"It's\", 'unfortunate', 'that', 'after', 'the', 'Stimulus', 'plan', 'was', 'put', 'in', 'place', 'twice', 'to', 'help', 'GM', 'on', 'the', 'back', 'of', 'the', 'American', 'people', 'has', 'led', 'to', 'the', 'inevitable']),\n",
       "       list(['Tell', 'me', 'again', 'why', 'we', 'are', 'giving', 'more', '$$', 'to', 'GM', 'We', 'should', 'use', 'that', '$', 'for', 'all', 'the', 'programs', 'that', 'support', 'the', 'unemployed']),\n",
       "       list(['oh', 'yes', 'but', 'if', 'GM', 'dies', 'it', 'will', 'only', 'be', 'worth', 'more', 'boo', 'hahaha']),\n",
       "       list(['Time', 'Warner', 'cable', 'is', 'down', 'again', '3rd', 'time', 'since', 'Memorial', 'Day', 'bummer']),\n",
       "       list(['I', 'would', 'rather', 'pay', 'reasonable', 'yearly', 'taxes', 'for', 'free', 'fast', 'internet', 'than', 'get', 'gouged', 'by', 'Time', 'Warner', 'for', 'a', 'slow', 'connection']),\n",
       "       list(['NOOOOOOO', 'my', 'DVR', 'just', 'died', 'and', 'I', 'was', 'only', 'half', 'way', 'through', 'the', 'EA', 'presser', 'Hate', 'you', 'Time', 'Warner']),\n",
       "       list(['F*ck', 'Time', 'Warner', 'Cable', 'You', 'f*cking', 'suck', 'balls', 'I', 'have', 'a', '$700', 'HD', 'tv', '&amp', 'my', 'damn', 'HD', 'channels', 'hardly', 'ever', 'come', 'in', 'Bullshit']),\n",
       "       list(['time', 'warner', 'has', 'the', 'worse', 'customer', 'service', 'ever', 'I', 'will', 'never', 'use', 'them', 'again']),\n",
       "       list(['Time', 'warner', 'is', 'the', 'devil', 'Worst', 'possible', 'time', 'for', 'the', 'Internet', 'to', 'go', 'out']),\n",
       "       list(['Fuck', 'no', 'internet', 'damn', 'time', 'warner']),\n",
       "       list(['time', 'warner', 'really', 'picks', 'the', 'worst', 'time', 'to', 'not', 'work', 'all', 'i', 'want', 'to', 'do', 'is', 'get', 'to', 'mtv', 'com', 'so', 'i', 'can', 'watch', 'the', 'hills', 'wtfffff']),\n",
       "       list(['I', 'hate', 'Time', 'Warner', 'Soooo', 'wish', 'I', 'had', 'Vios', 'Cant', 'watch', 'the', 'fricken', 'Mets', 'game', 'w/o', 'buffering', 'I', 'feel', 'like', 'im', 'watching', 'free', 'internet', 'porn']),\n",
       "       list(['Ahh', 'got', 'rid', 'of', 'stupid', 'time', 'warner', 'today', '&amp', 'now', 'taking', 'a', 'nap', 'while', 'the', 'roomies', 'cook', 'for', 'me', 'Pretty', 'good', 'end', 'for', 'a', 'monday', ':)']),\n",
       "       list(['Time', \"Warner's\", 'HD', 'line', 'up', 'is', 'crap']),\n",
       "       list(['is', 'being', 'fucked', 'by', 'time', 'warner', 'cable', 'didnt', 'know', 'modems', 'could', 'explode', 'and', 'Susan', 'Boyle', 'sucks', 'too']),\n",
       "       list(['Time', 'Warner', 'Cable', 'Pulls', 'the', 'Plug', 'on', \"'The\", 'Girlfriend', \"Experience'\", '-', 'www', 'tinyurl', 'com/m595fk']),\n",
       "       list(['Time', 'Warner', 'Cable', 'slogan', 'Where', 'calling', 'it', 'a', 'day', 'at', '2pm', 'Happens']),\n",
       "       list(['Rocawear', 'Heads', 'to', 'China', 'Building', '300', 'Stores', '-']),\n",
       "       list(['Climate', 'focus', 'turns', 'to', 'Beijing', 'The', 'United', 'Nations', 'the', 'US', 'and', 'European', 'governments', 'have', 'called', 'on', 'China', 'to', 'co-o']),\n",
       "       list(['myfoxdc', 'Barrie', 'Students', 'Back', 'from', 'Trip', 'to', 'China', 'A', 'Silver', 'Spring', 'high', \"school's\", 'class', 'trip', 'to', 'China', 'has', 'en']),\n",
       "       list(['Three', 'China', 'aerospace', 'giants', 'develop', 'Tianjin', 'Binhai', 'New', 'Area', '22', '9', 'B', 'yuan', 'invested']),\n",
       "       list(['GM', 'CEO', 'China', 'will', 'continue', 'to', 'be', 'key', 'partner']),\n",
       "       list(['RT', 'is', 'now', 'the', 'time', 'to', 'buy', 'a', 'GM', 'car']),\n",
       "       list(['Recovering', 'from', 'surgery', 'wishing', 'was', 'here', ':(']),\n",
       "       list(['My', 'wrist', 'still', 'hurts', 'I', 'have', 'to', 'get', 'it', 'looked', 'at', 'I', 'HATE', 'the', 'dr/dentist/scary', 'places', ':(', 'Time', 'to', 'watch', 'Eagle', 'eye', 'If', 'you', 'want', 'to', 'join', 'txt']),\n",
       "       list(['Dentist', 'tomorrow', 'Have', 'to', 'brush', 'well', 'in', 'the', 'morning', 'Like', 'I', 'make', 'my', 'hair', 'all', 'nice', 'before', 'I', 'get', 'it', 'cut', 'Why']),\n",
       "       list(['THE', 'DENTIST', 'LIED', '\"', 'U', \"WON'T\", 'FEEL', 'ANY', 'DISCOMORT', 'PROB', \"WON'T\", 'EVEN', 'NEED', 'PAIN', 'PILLS', 'MAN', 'U', 'TWIPPIN', 'THIS', 'SHIT', 'HURT', 'HOW', 'MANY', 'PILLS', 'CAN', 'I', 'TAKE']),\n",
       "       list(['my', 'dentist', 'is', 'great', 'but', \"she's\", 'expensive', '=(']),\n",
       "       list(['Pet', 'Dentist']),\n",
       "       list(['is', 'studing', 'math', ';)', 'tomorrow', 'exam', 'and', 'dentist', ':)']),\n",
       "       list(['my', 'dentist', 'was', 'wrong', 'WRONG']),\n",
       "       list(['Going', 'to', 'the', 'dentist', 'later', ':|']),\n",
       "       list(['Son', 'has', 'me', 'looking', 'at', 'cars', 'online', 'I', 'hate', 'car', 'shopping', 'Would', 'rather', 'go', 'to', 'the', 'dentist', 'Anyone', 'with', 'a', 'good', 'car', 'at', 'a', 'good', 'price', 'to', 'sell']),\n",
       "       list(['NCAA', 'Baseball', 'Super', 'Regional', '-', 'Rams', 'Club']),\n",
       "       list(['just', 'started', 'playing', 'Major', 'League', 'Baseball', '2K9']),\n",
       "       list(['Cardinals', 'baseball', 'advance', 'to', 'Super', 'Regionals', 'Face', 'CS-Fullerton', 'Friday']),\n",
       "       list(['Sony', 'coupon', 'code', 'Expires', 'soon']),\n",
       "       list(['waiting', 'in', 'line', 'at', 'safeway']),\n",
       "       list(['luke', 'and', 'i', 'got', 'stopped', 'walking', 'out', 'of', 'safeway', 'and', 'asked', 'to', 'empty', 'our', 'pockets', 'and', 'lift', 'our', 'shirts', 'how', 'jacked', 'up', 'is', 'that']),\n",
       "       list(['Did', 'not', 'realize', 'there', 'is', 'a', 'gym', 'above', 'Safeway']),\n",
       "       list(['I', 'have', 'three', 'words', 'for', 'you', 'Safeway', 'dot', 'com']),\n",
       "       list(['Safeway', 'is', 'very', 'rock', 'n', 'roll', 'tonight']),\n",
       "       list(['Bout', 'to', 'hit', 'safeway', 'I', 'gotta', 'eat']),\n",
       "       list([\"Jake's\", 'going', 'to', 'safeway']),\n",
       "       list(['Found', 'a', 'safeway', 'Picking', 'up', 'a', 'few', 'staples']),\n",
       "       list(['Safeway', 'Super-marketing', 'via', 'mobile', 'coupons']),\n",
       "       list(['The', 'safeway', 'bathroom', 'still', 'smells', 'like', 'ass']),\n",
       "       list(['At', 'safeway', 'on', 'elkhorn', 'they', 'move', 'like', \"they're\", 'dead']),\n",
       "       list(['Your', 'Normal', 'Weight', 'and', 'How', 'to', 'Get', 'There', '?', 'Normal', 'Eating', 'Blog']),\n",
       "       list(['Is', 'Eating', 'and', 'Watching', 'Movies']),\n",
       "       list(['eating', 'sashimi']),\n",
       "       list(['is', 'eating', 'home', 'made', 'yema']),\n",
       "       list(['eating', 'cake']),\n",
       "       list(['i', 'love', 'Dwight', \"Howard's\", 'vitamin', 'water', 'commercial', 'now', 'i', 'wish', 'he', 'was', 'with', 'NIKE', 'and', 'not', 'adidas', 'lol']),\n",
       "       list(['Found', 'NOTHING', 'at', 'Nike', 'Factory', ':/', 'Off', 'to', 'Banana', 'Republic', 'Outlet']),\n",
       "       list(['iPhone', 'May', 'Get', 'Radio', 'Tagging', 'and', 'Nike', ':', 'Recently-released', 'iTunes', 'version', '8', '2', 'suggests', 'that', 'VoiceOver', 'functional']),\n",
       "       list(['is', 'lovin', 'his', 'Nike', 'already', 'and', \"that's\", 'only', 'from', 'running', 'on', 'the', 'spot', 'in', 'his', 'bedroom']),\n",
       "       list(['Launched', 'imgsearch', 'ajax', 'jquery', 'webapp']),\n",
       "       list(['I', 'finally', 'got', 'around', 'to', 'using', 'jquery', 'to', 'make', 'my', 'bio', 'collapse', 'Yay', 'for', 'slide', 'animations']),\n",
       "       list(['RT', ':', 'The', 'Ultimate', 'jQuery', 'List', '-']),\n",
       "       list(['I', 'just', 'extracted', 'and', 'open-sourced', 'a', 'jQuery', 'plugin', 'from', 'Stormweight', 'to', 'highlight', 'text', 'with', 'a', 'regular', 'expression']),\n",
       "       list(['debenham', 'what', 'was', 'the', 'php', 'jquery', 'hack']),\n",
       "       list(['jQuery', 'Cheat', 'Sheet']),\n",
       "       list(['Beginning', 'JavaScript', 'and', 'CSS', 'Development', 'with', 'jQuery', 'javascript', 'css', 'jquery']),\n",
       "       list(['right', 'LOL', \"we'll\", 'get', 'there', 'I', 'have', 'high', 'expectations', 'Warren', 'Buffet', 'style']),\n",
       "       list(['RT', ':', 'RT', 'GREAT', \"Someone's\", 'sitting', 'in', 'the', 'shade', 'today', 'because', 'someone', 'planted', 'a', 'tree', 'a', 'long', 'time', 'ago', '\"-', 'Warren', 'Buffet']),\n",
       "       list(['Warren', 'Buffet', 'on', 'the', 'economy']),\n",
       "       list(['Warren', 'Buffet', 'became', 'for', 'a', 'time', 'the', 'richest', 'man', 'in', 'the', 'United', 'States', 'not', 'by', 'working', 'but', 'investing', 'in', '1', 'Big', 'idea', 'which', 'lead', 'to', 'the', 'fortune']),\n",
       "       list(['According', 'to', 'the', 'create', 'a', 'school', 'Notre', 'Dame', 'will', 'have', '7', 'receivers', 'in', 'NCAA', '10', 'at', '84', 'or', 'higher', 'rating', ':)', 'sweet']),\n",
       "       list(['All-Star', 'Basketball', 'Classic', 'Tuesday', 'Features', 'Top', 'Talent', \"Chattanooga's\", 'Notre', 'Dame', 'High', 'School', 'will', 'play', 'host']),\n",
       "       list([\"it's\", 'definitely', 'under', 'warranty', '&amp', 'my', 'experience', 'is', 'the', 'amazon', 'support', 'for', 'kindle', 'is', 'great', 'had', 'to', 'contact', 'them', 'about', 'my', 'kindle2']),\n",
       "       list(['RT', 'Look', 'Available', 'Amazon', 'Kindle2', '&amp', 'Kindle', 'DX', 'Get', 'it', 'Here', 'The', 'Top', 'Electronic', 'Book', 'Reader', 'Period', 'free', '2', 'day', 'ship']),\n",
       "       list(['Time', 'Warner', 'Road', 'Runner', 'customer', 'support', 'here', 'absolutely', 'blows', 'I', 'hate', 'not', 'having', 'other', 'high-speed', 'net', 'options', \"I'm\", 'ready', 'to', 'go', 'nuclear']),\n",
       "       list(['Time', 'Warner', 'cable', 'phone', 'reps', 'r', 'dumber', 'than', 'nails', 'UGH', 'Cable', 'was', 'working', '10', 'mins', 'ago', 'now', 'its', 'not', 'WTF']),\n",
       "       list(['we', 'tried', 'but', 'Time', 'Warner', \"wasn't\", 'being', 'nice', 'so', 'we', 'recorded', 'today', ':)']),\n",
       "       list(['OMG', '-', 'time', 'warner', \"f'ed\", 'up', 'my', 'internet', 'install', '-', 'instead', 'of', 'today', 'its', 'now', 'NEXT', 'saturday', '-', 'another', 'week', 'w/o', 'internet', '&amp;$*ehfa^V9fhg', 'fml']),\n",
       "       list(['wth', 'i', 'have', 'never', 'seen', 'a', 'line', 'this', 'loooong', 'at', 'time', 'warner', 'before', 'ugh']),\n",
       "       list(['Impatiently', 'awaiting', 'the', 'arrival', 'of', 'the', 'time', 'warner', 'guy', \"It's\", 'way', 'too', 'pretty', 'to', 'be', 'inside', 'all', 'afternoon']),\n",
       "       list(['Man', 'accosts', 'Roger', 'Federer', 'during', 'French', 'Open']),\n",
       "       list(['Naive', 'Bayes', 'using', 'EM', 'for', 'Text', 'Classification', 'Really', 'Frustrating']),\n",
       "       list(['We', 'went', 'to', 'Stanford', 'University', 'today', 'Got', 'a', 'tour', 'Made', 'me', 'want', 'to', 'go', 'back', 'to', 'college', \"It's\", 'also', 'decided', 'all', 'of', 'our', 'kids', 'will', 'go', 'there']),\n",
       "       list(['Investigation', 'pending', 'on', 'death', 'of', 'Stanford', 'CS', 'prof', '/', 'Google', 'mentor', 'Rajeev', 'Motwani', 'tip']),\n",
       "       list([\"I'm\", 'going', 'to', 'bed', 'It', 'was', 'a', 'successful', 'weekend', 'Stanford', 'here', 'I', 'come']),\n",
       "       list(['If', \"you're\", 'being', 'harassed', 'by', 'calls', 'about', 'your', 'car', 'warranty', 'changing', 'your', 'number', \"won't\", 'fix', 'that', 'They', 'call', 'every', 'number', 'd-bags']),\n",
       "       list(['Just', 'blocked', 'United', 'Blood', 'Services', 'using', 'Google', 'Voice', 'They', 'call', 'more', 'than', 'those', 'Car', 'Warranty', 'guys']),\n",
       "       list(['at&amp;t', 'is', 'complete', 'fail']),\n",
       "       list(['OH', 'SNAP', 'YOU', 'WORK', 'AT', 'AT&amp;T', \"DON'T\", 'YOU']),\n",
       "       list(['i', 'really', 'dont', 'want', 'AT&amp;T', 'phone', 'service', 'they', 'suck', 'when', 'it', 'comes', 'to', 'having', 'a', 'signal']),\n",
       "       list(['I', 'say', 'we', 'just', 'cut', 'out', 'the', 'small', 'talk', \"AT&amp;T's\", 'new', 'slogan', 'F__k', 'you', 'give', 'us', 'your', 'money', 'Apologies', 'to', 'Bob', 'Geldof', ')']),\n",
       "       list(['pissed', 'about', \"at&amp;t's\", 'mid-contract', 'upgrade', 'price', 'for', 'the', 'iPhone', \"it's\", '$200', 'more', \"I'm\", 'not', 'going', 'to', 'pay', '$499', 'for', 'something', 'I', 'thought', 'was', '$299']),\n",
       "       list(['Safari', '4', 'is', 'fast', ':)', 'Even', 'on', 'my', 'shitty', 'AT&amp;T', 'tethering']),\n",
       "       list(['What', 'is', 'AT&amp;T', 'fucking', 'up']),\n",
       "       list(['AT&amp;T', 'dropped', 'the', 'ball', 'and', \"isn't\", 'supporting', 'crap', 'with', 'the', 'new', 'iPhone', '3', '0', 'FAIL', 'att', 'SUCKS']),\n",
       "       list(['yay', 'glad', 'you', 'got', 'the', 'phone', 'Still', 'damn', 'you', 'AT&amp;T']),\n",
       "       list(['Google', 'Wave', 'Developer', 'Sandbox', 'Account', 'Request']),\n",
       "       list(['Talk', 'is', 'Cheap', 'Bing', 'that', 'I?ll', 'stick', 'with', 'Google']),\n",
       "       list(['WTF', 'is', 'the', 'point', 'of', 'deleting', 'tweets', 'if', 'they', 'can', 'still', 'be', 'found', 'in', 'summize', 'and', 'searches', 'Twitter', 'please', 'fix', 'that', 'Thanks', 'and', 'bye']),\n",
       "       list(['have', 'google', 'profiles', 'stopped', 'showing', 'up', 'in', 'searches', 'cant', 'see', 'them', 'anymore']),\n",
       "       list(['I', 'love', 'Google', 'Translator', 'too', '!', 'D', 'Good', 'day', 'mate', '!']),\n",
       "       list(['reading', 'on', 'my', 'new', 'Kindle2']),\n",
       "       list(['My', 'Kindle2', 'came', 'and', 'I', 'LOVE', 'it', ':)']),\n",
       "       list(['LOVING', 'my', 'new', 'Kindle2', 'Named', 'her', 'Kendra', 'in', 'case', 'u', 'were', 'wondering', 'The', 'cookbook', 'is', 'THE', 'tool', 'cuz', 'it', 'tells', 'u', 'all', 'the', 'tricks', 'Best', 'gift', 'EVR']),\n",
       "       list(['The', 'real', 'AIG', 'scandal', '/']),\n",
       "       list(['Any', 'twitter', 'to', 'aprs', 'apps', 'yet']),\n",
       "       list(['45', 'Pros', 'You', 'Should', 'Be', 'Following', 'on', 'Twitter', '-']),\n",
       "       list(['Obama', 'is', 'quite', 'a', 'good', 'comedian', 'check', 'out', 'his', 'dinner', 'speech', 'on', 'CNN', ':)', 'very', 'funny', 'jokes']),\n",
       "       list([\"'\", 'Barack', 'Obama', 'shows', 'his', 'funny', 'side', '\"', '&gt;&gt', '!!', 'Great', 'speech']),\n",
       "       list(['I', 'like', 'this', 'guy', ':', \"'\", 'Barack', 'Obama', 'shows', 'his', 'funny', 'side', '\"', '&gt;&gt', '!!']),\n",
       "       list([\"Obama's\", 'speech', 'was', 'pretty', 'awesome', 'last', 'night']),\n",
       "       list(['Reading', 'Bill', 'Clinton', 'Fail', '-', 'Obama', 'Win']),\n",
       "       list(['Obama', 'More', 'Popular', 'Than', 'U', 'S', 'Among', 'Arabs', 'Survey', 'President', 'Barack', \"Obama's\", 'popularity', 'in', 'leading', 'Arab', 'countries']),\n",
       "       list([\"Obama's\", 'got', 'JOKES', 'haha', 'just', 'got', 'to', 'watch', 'a', 'bit', 'of', 'his', 'after', 'dinner', 'speech', 'from', 'last', 'night', \"i'm\", 'in', 'love', 'with', 'mr', 'president', ';)']),\n",
       "       list(['LEbron', 'james', 'got', 'in', 'a', 'car', 'accident', 'i', 'guess', 'just', 'heard', 'it', 'on', 'evening', 'news', 'wow', 'i', 'cant', 'believe', 'it', 'will', 'he', 'be', 'ok', '?']),\n",
       "       list(['is', 'it', 'me', 'or', 'is', 'this', 'the', 'best', 'the', 'playoffs', 'have', 'been', 'in', 'years', 'oh', 'yea', 'lebron', 'and', 'melo', 'in', 'the', 'finals']),\n",
       "       list(['No', 'Lebron', 'is', 'the', 'best']),\n",
       "       list(['real_usher', 'LeBron', 'is', 'cool', 'I', 'like', 'his', 'personality', 'he', 'has', 'good', 'character']),\n",
       "       list(['Watching', 'Lebron', 'highlights', 'Damn', 'that', 'niggas', 'good']),\n",
       "       list(['Lebron', 'is', 'MURDERING', 'shit']),\n",
       "       list(['LeBron', 'is', 'a', 'monsta', 'and', 'he', 'is', 'only', '24', 'SMH', 'The', 'world', \"ain't\", 'ready']),\n",
       "       list(['when', 'Lebron', 'is', 'done', 'in', 'the', 'NBA', 'he', 'will', 'probably', 'be', 'greater', 'than', 'Kobe', 'Like', 'u', 'said', 'Kobe', 'is', 'good', 'but', 'there', 'alot', 'of', \"'good'\", 'players']),\n",
       "       list(['KOBE', 'IS', 'GOOD', 'BT', 'LEBRON', 'HAS', 'MY', 'VOTE']),\n",
       "       list(['Kobe', 'is', 'the', 'best', 'in', 'the', 'world', 'not', 'lebron']),\n",
       "       list(['World', 'Cup', '2010', 'Access', 'Damn', \"that's\", 'a', 'good', 'look']),\n",
       "       list(['Just', 'bought', 'my', 'tickets', 'for', 'the', '2010', 'FIFA', 'World', 'Cup', 'in', 'South', 'Africa', 'Its', 'going', 'to', 'be', 'a', 'great', 'summer']),\n",
       "       list(['Share', 'Disruption', 'Fred', \"Wilson's\", 'slides', 'for', 'his', 'talk', 'at', 'Google', 'HQ']),\n",
       "       list(['I', 'have', 'to', 'go', 'to', 'Booz', 'Allen', 'Hamilton', 'for', 'a', '2hr', 'meeting', ':(', 'But', 'then', 'i', 'get', 'to', 'go', 'home', ':)']),\n",
       "       list(['The', 'great', 'Indian', 'tamasha', 'truly', 'will', 'unfold', 'from', 'May', '16,', 'the', 'result', 'day', 'for', 'Indian', 'General', 'Election']),\n",
       "       list(['I', 'have', 'the', 'Kindle2', \"I've\", 'seen', 'pictures', 'of', 'the', 'DX', 'but', \"haven't\", 'seen', 'it', 'in', 'person', 'I', 'love', 'my', 'Kindle', '-', \"I'm\", 'on', 'it', 'everyday']),\n",
       "       list(['Such', 'an', 'awesome', 'idea', '-', 'the', 'continual', 'learning', 'program', 'with', 'a', 'Kindle2']),\n",
       "       list(['ok', 'do', 'nothing', 'just', 'thinking', 'about', '40D']),\n",
       "       list(['Ooooh', 'what', 'model', 'are', 'you', 'getting', 'I', 'have', 'the', '40D', 'and', 'LOVE', 'LOVE', 'LOVE', 'LOVE', 'it']),\n",
       "       list(['The', 'Times', 'of', 'India', 'The', 'wonder', 'that', 'is', \"India's\", 'election']),\n",
       "       list(['Good', 'video', 'from', 'Google', 'on', 'using', 'search', 'options']),\n",
       "       list(['lol', 'Ah', 'my', 'skin', 'is', 'itchy', ':(', 'damn', 'lawnmowing']),\n",
       "       list(['itchy', 'back', 'dont', 'ya', 'hate', 'it']),\n",
       "       list(['Stanford', 'Charity', 'Fashion', 'Show', 'a', 'top', 'draw']),\n",
       "       list(['Stanford', 'University?s', 'Facebook', 'Profile', 'is', 'One', 'of', 'the', 'Most', 'Popular', 'Official', 'University', 'Pages', '-']),\n",
       "       list(['Lyx', 'is', 'cool']),\n",
       "       list(['SOOO', 'DISSAPOiNTED', 'THEY', 'SENT', 'DANNY', 'GOKEY', 'HOME', 'YOU', 'STiLL', 'ROCK', 'DANNY', 'MY', 'HOMETOWN', 'HERO', '!!', 'YEAH', 'MiLROCKEE']),\n",
       "       list(['RT', \"'American\", \"Idol'\", 'fashion', 'Adam', 'Lambert', 'tones', 'down', 'Danny', 'Gokey', 'cute']),\n",
       "       list(['I', 'love', 'you', 'DANNY', 'GOKEY', ':)']),\n",
       "       list(['RT', ':', 'RT', 'GM', 'OnStar', 'now', 'instantly', 'sends', 'accident', 'location', 'coordinates', 'to', '911', '|', 'GPS', 'Obsessed']),\n",
       "       list(['so', 'tired', 'i', \"didn't\", 'sleep', 'well', 'at', 'all', 'last', 'night']),\n",
       "       list(['Boarding', 'plane', 'for', 'San', 'Francisco', 'in', '1', 'hour', '6', 'hr', 'flight', 'Blech']),\n",
       "       list(['bonjour', 'San', 'Francisco', 'My', 'back', 'hurts', 'from', 'last', 'night']),\n",
       "       list(['breakers', 'in', 'San', 'Francisco', 'CA']),\n",
       "       list(['Heading', 'to', 'San', 'Francisco']),\n",
       "       list(['With', 'my', 'best', 'girl', 'for', 'a', 'few', 'more', 'hours', 'in', 'San', 'francisco', 'Mmmmmfamily', 'is', 'wonderful']),\n",
       "       list(['F', 'up', 'big', 'or', 'go', 'home', '-', 'AIG']),\n",
       "       list(['Went', 'to', 'see', 'the', 'Star', 'Trek', 'movie', 'last', 'night', 'Very', 'satisfying']),\n",
       "       list(['I', \"can't\", 'wait', 'going', 'to', 'see', 'star', 'trek', 'tonight']),\n",
       "       list(['Star', 'Trek', 'was', 'as', 'good', 'as', 'everyone', 'said']),\n",
       "       list(['am', 'loving', 'new', 'malcolm', 'gladwell', 'book', '-', 'outliers']),\n",
       "       list(['I', 'highly', 'recommend', 'Malcolm', \"Gladwell's\", \"'The\", 'Tipping', 'Point', \"'\", 'My', 'next', 'audiobook', 'will', 'probably', 'be', 'one', 'of', 'his', 'as', 'well']),\n",
       "       list(['Malcolm', 'Gladwell', 'is', 'a', 'genius', 'at', 'tricking', 'people', 'into', 'not', 'realizing', \"he's\", 'a', 'fucking', 'idiot']),\n",
       "       list(['hey', 'no', 'offense', 'but', 'malcolm', 'gladwell', 'is', 'a', 'pretenious', 'annoying', 'cunt', 'and', 'he', 'brings', 'you', 'down', 'cant', 'read', 'his', 'shit']),\n",
       "       list(['RT', ':', 'Great', 'article', 'by', 'Malcolm', 'Gladwell']),\n",
       "       list(['I', 'seriously', 'underestimated', 'Malcolm', 'Gladwell', 'I', 'want', 'to', 'meet', 'this', 'dude']),\n",
       "       list(['i', 'hate', 'comcast', 'right', 'now', 'everything', 'is', 'down', 'cable', 'internet', '&amp', 'phone', 'ughh', 'what', 'am', 'i', 'to', 'do']),\n",
       "       list(['Comcast', 'sucks']),\n",
       "       list(['The', 'day', 'I', 'never', 'have', 'to', 'deal', 'with', 'Comcast', 'again', 'will', 'rank', 'as', 'one', 'of', 'the', 'best', 'days', 'of', 'my', 'life']),\n",
       "       list(['did', 'comcast', 'fail', 'again']),\n",
       "       list(['How', 'do', 'you', 'use', 'the', 'twitter', 'API']),\n",
       "       list(['curses', 'the', 'Twitter', 'API', 'limit']),\n",
       "       list(['Now', 'I', 'can', 'see', 'why', 'Dave', 'Winer', 'screams', 'about', 'lack', 'of', 'Twitter', 'API', 'its', 'limitations', 'and', 'access', 'throttles']),\n",
       "       list(['testing', 'Twitter', 'API']),\n",
       "       list(['Arg', 'Twitter', 'API', 'is', 'making', 'me', 'crazy']),\n",
       "       list(['Testing', 'Twitter', 'API', 'Remote', 'Update']),\n",
       "       list([\"I'm\", 'really', 'loving', 'the', 'new', 'search', 'site', 'Wolfram/Alpha', 'Makes', 'Google', 'seem', 'so', 'quaint']),\n",
       "       list(['wolfram', 'Alpha', 'SUCKS', 'Even', 'for', 'researchers', 'the', 'information', 'provided', 'is', 'less', 'than', 'you', 'can', 'get', 'from', 'google', 'or', 'wikipedia', 'totally', 'useless']),\n",
       "       list(['Off', 'to', 'the', 'NIKE', 'factory']),\n",
       "       list(['New', 'nike', 'muppet', 'commercials', 'are', 'pretty', 'cute', 'Why', 'do', 'we', 'live', 'together', 'again']),\n",
       "       list(['New', 'blog', 'post', 'Nike', 'Zoom', 'LeBron', 'Soldier', '3', 'III', '-', 'White', '/', 'Black', '-', 'Teal']),\n",
       "       list(['New', 'blog', 'post', 'Nike', 'Trainer', '1']),\n",
       "       list(['oh', 'those', 'are', 'awesome', 'i', 'so', 'wish', 'they', \"weren't\", 'owned', 'by', 'nike', ':(']),\n",
       "       list(['-', 'AWESOME', 'Seeing', 'the', 'show', 'Friday', 'at', 'the', 'Shoreline', 'Amphitheatre', 'Never', 'seen', 'NIN', 'before', \"Can't\", 'wait']),\n",
       "       list(['arhh', \"It's\", 'weka', 'bug', '=', '=\"', 'and', 'I', 'spent', 'almost', 'two', 'hours', 'to', 'find', 'that', 'out', 'crappy', 'me']),\n",
       "       list(['hey', 'bud', ':)', 'np', 'I', 'do', 'so', 'love', 'my', '50D', 'although', \"I'd\", 'love', 'a', '5D', 'mkII', 'more']),\n",
       "       list(['just', 'got', 'us', 'a', '50D', 'for', 'the', 'office', 'D']),\n",
       "       list(['Just', 'picked', 'up', 'my', 'new', 'Canon', '50D', \"it's\", 'beautiful', 'Prepare', 'for', 'some', 'seriously', 'awesome', 'photography']),\n",
       "       list(['Just', 'got', 'my', 'new', 'toy', 'Canon', '50D', 'Love', 'love', 'love', 'it']),\n",
       "       list(['Learning', 'about', 'lambda', 'calculus', ':)']),\n",
       "       list(['jobs', 'sittercity', 'Help', 'with', 'taking', 'care', 'of', 'sick', 'child', 'East', 'Palo', 'Alto', 'CA']),\n",
       "       list([\"I'm\", 'moving', 'to', 'East', 'Palo', 'Alto']),\n",
       "       list(['@', 'atebits', 'I', 'just', 'finished', 'watching', 'your', 'Stanford', 'iPhone', 'Class', 'session', 'I', 'really', 'appreciate', 'it', 'You', 'Rock']),\n",
       "       list(['Hi', 'Just', 'saw', 'your', 'Stanford', 'talk', 'and', 'really', 'liked', 'your', 'advice', 'Just', 'saying', 'Hi', 'from', 'Singapore', 'yes', 'the', 'videos', 'do', 'get', 'around']),\n",
       "       list(['MBA', 'Admissions', 'Tips', 'Stanford', 'GSB', 'Deadlines', 'and', 'Essay', 'Topics', '2009-2010']),\n",
       "       list(['Ethics', 'and', 'nonprofits', '-', 'stanford', 'socialentrepreneurship']),\n",
       "       list(['LAKERS', 'tonight', \"let's\", 'go']),\n",
       "       list(['Will', 'the', 'Lakers', 'kick', 'the', 'Nuggets', 'ass', 'tonight']),\n",
       "       list(['Oooooooh', 'North', 'Korea', 'is', 'in', 'troubleeeee']),\n",
       "       list(['Wat', 'the', 'heck', 'is', 'North', 'Korea', 'doing', 'They', 'just', 'conducted', 'powerful', 'nuclear', 'tests', 'Follow', 'the', 'link']),\n",
       "       list(['Listening', 'to', 'Obama', 'Friggin', 'North', 'Korea']),\n",
       "       list(['I', 'just', 'realized', 'we', 'three', 'monkeys', 'in', 'the', 'white', 'Obama', 'Biden,Pelosi', 'Sarah', 'Palin', '2012']),\n",
       "       list(['Pelosi', 'should', 'stay', 'in', 'China', 'and', 'never', 'come', 'back']),\n",
       "       list(['Nancy', 'Pelosi', 'gave', 'the', 'worst', 'commencement', 'speech', \"I've\", 'ever', 'heard', 'Yes', \"I'm\", 'still', 'bitter', 'about', 'this']),\n",
       "       list(['ugh', 'the', 'amount', 'of', 'times', 'these', 'stupid', 'insects', 'have', 'bitten', 'me', 'Grr']),\n",
       "       list(['Prettiest', 'insects', 'EVER', '-', 'Pink', 'Katydids']),\n",
       "       list(['Just', 'got', 'barraged', 'by', 'a', 'horde', 'of', 'insects', 'hungry', 'for', 'my', 'kitchen', 'light', 'So', 'scary']),\n",
       "       list(['Just', 'had', 'McDonalds', 'for', 'dinner', 'D', 'It', 'was', 'goooood', 'Big', 'Mac', 'Meal', ';)']),\n",
       "       list(['AHH', 'YES', 'LOL', 'IMA', 'TELL', 'MY', 'HUBBY', 'TO', 'GO', 'GET', 'ME', 'SUM', 'MCDONALDS', '=]']),\n",
       "       list(['Stopped', 'to', 'have', 'lunch', 'at', 'McDonalds', 'Chicken', 'Nuggetssss', ':)', 'yummmmmy']),\n",
       "       list(['Could', 'go', 'for', 'a', 'lot', 'of', 'McDonalds', 'i', 'mean', 'A', 'LOT']),\n",
       "       list(['my', 'exam', 'went', 'good', ':', 'your', 'prayers', 'worked', '(:']),\n",
       "       list(['Only', 'one', 'exam', 'left', 'and', 'i', 'am', 'so', 'happy', 'for', 'it', 'D']),\n",
       "       list(['Math', 'review', 'Im', 'going', 'to', 'fail', 'the', 'exam']),\n",
       "       list(['Colin', 'Powell', 'rocked', 'yesterday', 'on', 'CBS', 'Cheney', 'needs', 'to', 'shut', 'the', 'hell', 'up', 'and', 'go', 'home', 'Powell', 'is', 'a', 'man', 'of', 'Honor', 'and', 'served', 'our', 'country', 'proudly']),\n",
       "       list(['obviously', 'not', 'siding', 'with', 'Cheney', 'here']),\n",
       "       list(['Absolutely', 'hilarious', 'from', ':']),\n",
       "       list(['I', 'never', 'did', 'thank', 'you', 'for', 'including', 'me', 'in', 'your', 'Top', '100', 'Twitter', 'Authors', 'You', 'Rock', '&amp', 'I', 'New', 'Wave', 'D']),\n",
       "       list(['Learning', 'jQuery', '1', '3', 'Book', 'Review', '-']),\n",
       "       list(['RT', ':', 'Awesome', 'JQuery', 'reference', 'book', 'for', 'Coda', 'webdesign']),\n",
       "       list([\"I've\", 'been', 'sending', 'e-mails', 'like', 'crazy', 'today', 'to', 'my', 'contacts', 'does', 'anyone', 'have', 'a', 'contact', 'at', 'Goodby', 'SIlverstein', \"I'd\", 'love', 'to', 'speak', 'to', 'them']),\n",
       "       list(['Adobe', 'CS4', 'commercial', 'by', 'Goodby', 'Silverstein']),\n",
       "       list(['Goodby', \"Silverstein's\", 'new', 'site', 'I', 'enjoy', 'it']),\n",
       "       list(['Wow', 'everyone', 'at', 'the', 'Google', 'I/O', 'conference', 'got', 'free', \"G2's\", 'with', 'a', 'month', 'of', 'unlimited', 'service']),\n",
       "       list(['dood', 'I', 'got', 'a', 'free', 'google', 'android', 'phone', 'at', 'the', 'I/O', 'conference', 'The', 'G2']),\n",
       "       list(['the', 'G2', 'is', 'amazing', 'btw', 'a', 'HUGE', 'improvement', 'over', 'the', 'G1']),\n",
       "       list(['HTML', '5', 'Demos', 'Lots', 'of', 'great', 'stuff', 'to', 'come', 'Yes', \"I'm\", 'excited', ':)', 'io2009', 'googleio']),\n",
       "       list(['-', 'Yay', 'Happy', 'place', 'Place', 'place', 'I', 'love', 'Google']),\n",
       "       list(['GoogleIO', '|', 'O3D', '-', 'Bringing', '3d', 'graphics', 'to', 'the', 'browser', 'Very', 'nice', 'tbh', 'Funfun']),\n",
       "       list(['Awesome', 'viral', 'marketing', 'for', 'Funny', 'People']),\n",
       "       list(['Watching', 'a', 'programme', 'about', 'the', 'life', 'of', 'Hitler', 'its', 'only', 'enhancing', 'my', 'geekiness', 'of', 'history']),\n",
       "       list(['saw', 'night', 'at', 'the', 'museum', 'out', 'of', 'sheer', 'desperation', 'who', 'is', 'funding', 'these', 'movies']),\n",
       "       list(['Night', 'At', 'The', 'Museum', '2?', 'Pretty', 'furkin', 'good']),\n",
       "       list(['Watching', 'Night', 'at', 'the', 'Museum', '-', 'giggling']),\n",
       "       list(['Jenna', 'I', 'went', 'to', 'see', 'Night', 'At', 'The', 'Museum', '2', 'today', 'and', 'I', 'was', 'so', 'surprised', 'to', 'see', 'three', 'cast', 'members', 'from', 'The', 'Office']),\n",
       "       list(['About', 'to', 'watch', 'Night', 'at', 'the', 'Museum', 'with', 'Ryan', 'and', 'Stacy']),\n",
       "       list(['Getting', 'ready', 'to', 'go', 'watch', 'Night', 'at', 'the', 'Museum', '2', 'Dum', 'dum', 'you', 'give', 'me', 'gum', 'gum']),\n",
       "       list(['Back', 'from', 'seeing', \"'Star\", \"Trek'\", 'and', \"'Night\", 'at', 'the', 'Museum', \"'\", \"'Star\", \"Trek'\", 'was', 'amazing', 'but', \"'Night\", 'at', 'the', \"Museum'\", 'was', 'eh']),\n",
       "       list(['just', 'watched', 'night', 'at', 'the', 'museum', '2!', 'so', 'stinkin', 'cute']),\n",
       "       list(['So', 'Night', 'at', 'the', 'Museum', '2', 'was', 'AWESOME', 'Much', 'better', 'than', 'part', '1', 'Next', 'weekend', \"we'll\", 'see', 'Up']),\n",
       "       list(['I', 'think', 'I', 'may', 'have', 'a', 'new', 'favorite', 'restaurant', 'On', 'our', 'way', 'to', 'see', 'Night', 'at', 'the', 'Museum', '2\"']),\n",
       "       list(['UP', 'was', 'sold', 'out', 'so', \"i'm\", 'seeing', 'Night', 'At', 'The', 'Museum', '2', \"I'm\", '__', 'years', 'old']),\n",
       "       list(['saw', 'the', 'new', 'Night', 'at', 'the', 'Museum', 'and', 'i', 'loved', 'it', 'Next', 'is', 'to', 'go', 'see', 'UP', 'in', '3D']),\n",
       "       list(['It', 'is', 'a', 'shame', 'about', 'GM', 'What', 'if', 'they', 'are', 'forced', 'to', 'make', 'only', 'cars', 'the', 'White', 'House', 'THINKS', 'will', 'sell', 'What', 'do', 'you', 'think']),\n",
       "       list(['As', 'u', 'may', 'have', 'noticed', 'not', 'too', 'happy', 'about', 'the', 'GM', 'situation', 'nor', 'AIG', 'Lehman', 'et', 'al']),\n",
       "       list(['Obama', 'Nationalization', 'of', 'GM', 'to', 'be', 'short-term', 'AP']),\n",
       "       list(['GM', 'good', 'riddance', 'sad', 'though']),\n",
       "       list(['I', 'Will', 'NEVER', 'Buy', 'a', 'Government', 'Motors', 'Vehicle', 'Until', 'just', 'recently', 'I', 'drove', 'GM', 'cars', 'Since', '1988,', 'when', 'I', 'bought', 'a']),\n",
       "       list(['Having', 'the', 'old', 'Coca-Cola', 'guy', 'on', 'the', 'GM', 'board', 'is', 'stupid', 'has', 'heck', 'tcot', 'ala']),\n",
       "       list(['RantsAndRaves', 'The', 'worst', 'thing', 'about', 'GM', 'concord', '/', 'pleasant', 'hill', '/', 'martinez', 'is', 'the', 'fucking', 'UAW']),\n",
       "       list(['Give', 'a', 'man', 'a', 'fish', 'u', 'feed', 'him', 'for', 'the', 'day', 'Teach', 'him', 'to', 'fish', 'u', 'feed', 'him', 'for', 'life', 'Buy', 'him', 'GM', 'and', 'u', 'F**K', 'him', 'over', 'for', 'good']),\n",
       "       list(['The', 'more', 'I', 'hear', 'about', 'this', 'GM', 'thing', 'the', 'more', 'angry', 'I', 'get', 'Billions', 'wasted', 'more', 'bullshit', 'All', 'for', 'something', 'like', '40k', 'employees', 'and', 'all', 'the']),\n",
       "       list(['i', 'own', 'a', 'GM', 'car', 'and', 'it', 'is', 'junk', 'as', 'far', 'as', 'quality', 'compared', 'to', 'a', 'honda']),\n",
       "       list(['sad', 'day', 'bankrupt', 'GM']),\n",
       "       list(['is', 'upset', 'about', 'the', 'whole', 'GM', 'thing', 'life', 'as', 'i', 'know', 'it', 'is', 'so', 'screwed', 'up']),\n",
       "       list(['whoever', 'is', 'running', 'time', 'warner', 'needs', 'to', 'be', 'repeatedly', 'raped', 'by', 'a', 'rhino', 'so', 'they', 'understand', 'the', 'consequences', 'of', 'putting', 'out', 'shitty', 'cable', 'svcs']),\n",
       "       list(['Time', 'Warner', 'CEO', 'hints', 'at', 'online', 'fees', 'for', 'magazines', 'AP', '-', 'Read', 'from', 'Mountain', 'View,United', 'States', 'Views', '16209']),\n",
       "       list(['WFTB', 'Joining', 'a', 'bit', 'late', 'My', 'connection', 'was', 'down', 'boo', 'time', 'warner']),\n",
       "       list(['Cox', 'or', 'Time', 'Warner', 'Cox', 'is', 'cheaper', 'and', 'gets', 'a', 'B', 'on', 'dslreports', 'TW', 'is', 'more', 'expensive', 'and', 'gets', 'a', 'C']),\n",
       "       list(['i', 'am', 'furious', 'with', 'time', 'warner', 'and', 'their', 'phone', 'promotions']),\n",
       "       list(['Just', 'got', 'home', 'from', 'chick-fil-a', 'with', 'the', 'boys', 'Damn', 'my', 'internets', 'down', '=(', 'stupid', 'time', 'warner']),\n",
       "       list(['could', 'time-warner', 'cable', 'suck', 'more', 'NO']),\n",
       "       list(['Pissed', 'at', 'Time', 'Warner', 'for', 'causin', 'me', 'to', 'have', 'slow', 'internet', 'problems']),\n",
       "       list(['Ummm', 'having', 'some', 'Time', 'Warner', 'problems']),\n",
       "       list(['You', 'guys', 'see', 'this', 'Why', 'does', 'Time', 'Warner', 'have', 'to', 'suck', 'so', 'much', 'ass', 'Really', 'wish', 'I', 'could', 'get', 'U-Verse', 'at', 'my', 'apartment']),\n",
       "       list(['RT', 'The', 'upside', 'to', 'Time', 'Warner', 'unhelpful', 'phone', 'operators', 'superslow', 'on-site', 'service', 'Crap', \"that's\", 'not', 'an', 'upside']),\n",
       "       list(['RT', ':', 'New', 'Time', 'Warner', 'slogan', 'Time', 'Warner', 'where', 'we', 'make', 'you', 'long', 'for', 'the', 'days', 'before', 'cable', '\"']),\n",
       "       list(['confirmed', \"it's\", 'Time', \"Warner's\", 'fault', 'not', \"Facebook's\", 'that', 'fb', 'is', 'taking', 'about', '3', 'minutes', 'to', 'load', 'so', 'tempted', 'to', 'switch', 'to', 'verizon', '=/']),\n",
       "       list(['Time', 'Warner', '=', 'epic', 'fail']),\n",
       "       list(['Lawson', 'to', 'head', 'Newedge', 'Hong', 'Kong', 'business', 'china']),\n",
       "       list(['Weird', 'Piano', 'Guitar', 'House', 'in', 'China']),\n",
       "       list(['Send', 'us', 'your', 'GM/Chevy', 'photos']),\n",
       "       list(['I', 'know', 'How', 'sad', 'is', 'that', 'RT', ':', '1st', 'day', 'of', 'hurricane', 'season', \"That's\", 'less', 'scarey', 'than', 'govt', 'taking', 'over', 'GM']),\n",
       "       list(['GM', 'files', 'Bankruptcy', 'not', 'a', 'good', 'sign']),\n",
       "       list(['yankees', 'won', 'mets', 'lost', 'its', 'a', 'good', 'day']),\n",
       "       list(['My', 'dentist', 'appt', 'today', 'was', 'actually', 'quite', 'enjoyable']),\n",
       "       list(['I', 'hate', 'the', 'effing', 'dentist']),\n",
       "       list(['i', 'had', 'a', 'dentist', 'appt', 'this', 'morning', 'and', 'had', 'the', 'same', 'conversation']),\n",
       "       list(['I', 'hate', 'going', 'to', 'the', 'dentist', '!!!']),\n",
       "       list(['i', 'hate', 'the', 'dentist', 'who', 'invented', 'them', 'anyways']),\n",
       "       list(['this', \"dentist's\", 'office', 'is', 'cold', ':/']),\n",
       "       list(['Check', 'this', 'video', 'out', '--', 'David', 'After', 'Dentist']),\n",
       "       list(['First', 'dentist', 'appointment', 'in', 'years', 'on', 'Wednesday', 'possibly']),\n",
       "       list(['Tom', \"Shanahan's\", 'latest', 'column', 'on', 'SDSU', 'and', 'its', 'NCAA', 'Baseball', 'Regional', 'appearance']),\n",
       "       list(['BaseballAmerica', 'com', 'Blog', 'Baseball', 'America', 'Prospects', 'Blog', '?', 'Blog']),\n",
       "       list(['Portland', 'city', 'politics', 'may', 'undo', 'baseball', 'park']),\n",
       "       list(['RT', ':', 'CA', \"Merced's\", 'water', 'bottled', 'by', 'Safeway', 'resold', 'at', 'a', 'profit', 'Wells', 'are', 'drying', 'up', 'across', 'the', 'county']),\n",
       "       list(['dropped', 'her', 'broccoli', 'walking', 'home', 'from', 'safeway', ';(', 'so', 'depressed']),\n",
       "       list(['we', \"don't\", 'have', 'Safeway']),\n",
       "       list(['Just', 'applied', 'at', 'Safeway', 'Yeeeee']),\n",
       "       list(['@', 'Safeway', 'Place', 'is', 'a', 'nightmare', 'right', 'now', 'Bumming']),\n",
       "       list(['at', 'safeway', 'with', 'dad']),\n",
       "       list(['HATE', 'safeway', 'select', 'green', 'tea', 'icecream', 'bought', 'two', 'cartons', 'what', 'a', 'waste', 'of', 'money', '&gt;_&lt']),\n",
       "       list(['Safeway', 'with', 'Marvin', 'Janelle', 'and', 'Auntie', 'Lhu']),\n",
       "       list(['Safeway', 'offering', 'mobile', 'coupons']),\n",
       "       list(['Phillies', 'Driving', 'in', 'the', 'Cadillac', 'with', 'the', 'Top', 'Down', 'in', 'Cali', 'Win', '5-3', '-']),\n",
       "       list(['Saved', 'money', 'by', 'opting', 'for', 'grocery', 'store', 'trip', 'and', 'stocking', 'food', 'in', 'hotel', 'room', 'fridge', 'vs', 'eating', 'out', 'every', 'night', 'while', 'out', 'of', 'town']),\n",
       "       list(['Lounging', 'around', 'eating', 'Taco', 'Bell', 'and', 'watching', 'NCIS', 'before', 'work', 'tonight', 'Need', 'help', 'staying', 'awake']),\n",
       "       list(['eating', 'breakfast', 'and', 'then', 'school']),\n",
       "       list(['still', 'hungry', 'after', 'eating']),\n",
       "       list(['10', 'tips', 'for', 'healthy', 'eating', '?', 'ResultsBy', 'Fitness', 'Blog', '::', 'Fitness']),\n",
       "       list(['with', 'the', 'boyfriend', 'eating', 'a', 'quesadilla']),\n",
       "       list(['Eating', 'dinner', 'Meat', 'chips', 'and', 'risotto']),\n",
       "       list(['got', 'a', 'new', 'pair', 'of', 'nike', 'shoes', 'pics', 'up', 'later']),\n",
       "       list(['Nike', 'SB', 'Blazer', 'High', 'ACG', 'Custom', '-', 'Brad', 'Douglas', '-']),\n",
       "       list(['Nike', 'rocks', \"I'm\", 'super', 'grateful', 'for', 'what', \"I've\", 'done', 'with', 'them', ':)', '&amp', 'the', 'European', 'Division', 'of', 'NIKE', 'is', 'BEYOND']),\n",
       "       list(['Nike', 'Air', 'Yeezy', 'Khaki/Pink', 'Colorway', 'Release', '-']),\n",
       "       list(['have', 'you', 'tried', 'Nike', '?', 'V', 'addictive']),\n",
       "       list(['That', 'looks', 'an', 'awful', 'lot', 'like', 'one', 'of', \"Nike's\", 'private', 'jets', \"I'm\", 'just', 'sayin']),\n",
       "       list(['The', 'Nike', 'Training', 'Club', 'beta', 'iPhone', 'app', 'looks', 'very', 'interesting']),\n",
       "       list(['argghhhh', 'why', \"won't\", 'my', 'jquery', 'appear', 'in', 'safari', 'bad', 'safari', '!!!']),\n",
       "       list(['DevSnippets', ':', 'jQuery', 'Tools', '-', 'Javascript', 'UI', 'Components', 'for', 'the', 'Web']),\n",
       "       list(['all', 'about', 'Ajax,jquery', 'css', 'JavaScript', 'and', 'more', 'many', 'examples']),\n",
       "       list([\"I'm\", 'ready', 'to', 'drop', 'the', 'pretenses', 'I', 'am', 'forever', 'in', 'love', 'with', 'jQuery', 'and', 'I', 'want', 'to', 'marry', 'it', 'Sorry', 'ladies', 'this', 'nerd', 'is', 'jquery', 'spokenFor', 'js']),\n",
       "       list(['This', 'is', 'cold', 'I', 'was', 'looking', 'at', \"google's\", 'chart//visualization', 'API', 'and', 'found', 'this', 'jQuery', 'wrapper', 'for', 'the', 'API']),\n",
       "       list(['I', 'spent', 'most', 'of', 'my', 'day', 'reading', 'a', 'jQuery', 'book', 'Now', 'to', 'start', 'drinking', 'some', 'delirium', 'tremens']),\n",
       "       list(['jquery', 'Selectors']),\n",
       "       list(['How', 'to', 'implement', 'a', 'news', 'ticker', 'with', 'jQuery', 'and', 'ten', 'lines', 'of', 'code']),\n",
       "       list([\"What's\", 'Buffet', 'Doing', 'Warren', 'Buffett', 'Kicks', 'Butt', 'In', 'Battle', 'of', 'the', 'Boots', 'Posted', 'By:Alex', 'Crippe']),\n",
       "       list(['SUPER', 'INVESTORS', 'A', 'great', 'weekend', 'read', 'here', 'from', 'Warren', 'Buffet', 'Oldie', 'but', 'a', 'goodie']),\n",
       "       list([\"I'm\", 'truly', 'braindead', 'I', \"couldn't\", 'come', 'up', 'with', 'Warren', \"Buffet's\", 'name', 'to', 'save', 'my', 'soul']),\n",
       "       list(['reading', 'Michael', 'Palin', 'book', 'The', 'Python', 'Years', 'great', 'book', 'I', 'also', 'recommend', 'Warren', 'Buffet', '&amp', 'Nelson', \"Mandela's\", 'bio']),\n",
       "       list(['I', 'mean', \"I'm\", 'down', 'with', 'Notre', 'Dame', 'if', 'I', 'have', 'to', \"It's\", 'a', 'good', 'school', \"I'd\", 'be', 'closer', 'to', 'Dan', \"I'd\", 'enjoy', 'it']),\n",
       "       list(['I', \"can't\", 'watch', 'TV', 'without', 'a', 'Tivo', 'And', 'after', 'all', 'these', 'years', 'the', 'Time/Warner', 'DVR', 'STILL', 'sucks']),\n",
       "       list([\"I'd\", 'say', 'some', 'sports', 'writers', 'are', 'idiots', 'for', 'saying', 'Roger', 'Federer', 'is', 'one', 'of', 'the', 'best', 'ever', 'in', 'Tennis', 'Roger', 'Federer', 'is', 'THE', 'best', 'ever', 'in', 'Tennis']),\n",
       "       list(['I', 'still', 'love', 'my', 'Kindle2', 'but', 'reading', 'The', 'New', 'York', 'Times', 'on', 'it', 'does', 'not', 'feel', 'natural', 'I', 'miss', 'the', 'Bloomingdale', 'ads']),\n",
       "       list(['I', 'love', 'my', 'Kindle2', 'No', 'more', 'stacks', 'of', 'books', 'to', 'trip', 'over', 'on', 'the', 'way', 'to', 'the', 'loo']),\n",
       "       list(['Although', \"today's\", 'keynote', 'rocked', 'for', 'every', 'great', 'announcement', 'AT&amp;T', 'shit', 'on', 'us', 'just', 'a', 'little', 'bit', 'more']),\n",
       "       list(['-', 'its', 'not', 'so', 'much', 'my', 'obsession', 'with', 'cell', 'phones', 'but', 'the', 'iphone', \"i'm\", 'a', 'slave', 'to', 'at&amp;t', 'forever', 'because', 'of', 'it', ':)']),\n",
       "       list(['oh', 'I', 'see', 'I', 'thought', 'AT&amp;T', 'were', '900MHz', 'WCDMA']),\n",
       "       list(['Where', 'did', 'you', 'read', 'about', 'tethering', 'support', 'Phil', 'Just', 'AT&amp;T', 'or', 'will', 'O2', 'be', 'joining', 'in']),\n",
       "       list(['Fuzzball', 'is', 'more', 'fun', 'than', 'AT&amp;T', 'P']),\n",
       "       list(['Today', 'is', 'a', 'good', 'day', 'to', 'dislike', 'AT&amp;T', 'Vote', 'out', 'of', 'office', 'indeed']),\n",
       "       list(['GOT', 'MY', 'WAVE', 'SANDBOX', 'INVITE', 'Extra', 'excited', 'Too', 'bad', 'I', 'have', 'class', 'now', 'but', \"I'll\", 'play', 'with', 'it', 'soon', 'enough', 'io2009', 'wave']),\n",
       "       list(['looks', 'like', 'summize', 'has', 'gone', 'down', 'too', 'many', 'tweets', 'from', 'WWDC', 'perhaps']),\n",
       "       list(['I', 'hope', 'the', 'girl', 'at', 'work', 'buys', 'my', 'Kindle2']),\n",
       "       list(['Missed', 'this', 'insight-filled', 'May', 'column', 'One', 'smart', 'guy', 'looking', 'closely', 'at', 'why', \"he's\", 'impressed', 'with', 'Kindle2']),\n",
       "       list(['Thanks', 'so', 'much', 'from', 'one', 'of', 'your', 'very', 'happy', 'Kindle2', 'winners', ';', ')', 'I', 'was', 'so', 'surprised', 'fabulous', 'Thank', 'you', 'Best', 'Kathleen']),\n",
       "       list(['Man', 'I', 'kinda', 'dislike', 'Apple', 'right', 'now', 'Case', 'in', 'point', 'the', 'iPhone', '3GS', 'Wish', 'there', 'was', 'a', 'video', 'recorder', 'app', 'Please']),\n",
       "       list(['I', 'have', 'a', 'Kindle2', '&amp', 'Sony', 'PRS-500', 'Like', 'it', 'Physical', 'device', 'feels', 'good', 'Font', 'is', 'nice', 'Pg', 'turns', 'are', 'snappy', 'enuf', 'UI', 'a', 'little', 'klunky']),\n",
       "       list(['The', 'Kindle2', 'seems', 'the', 'best', 'eReader', 'but', 'will', 'it', 'work', 'in', 'the', 'UK', 'and', 'where', 'can', 'I', 'get', 'one']),\n",
       "       list(['I', 'have', 'a', 'google', 'addiction', 'Thank', 'you', 'for', 'pointing', 'that', 'out', 'Hahaha']),\n",
       "       list(['gem', 'My', 'primary', 'debit', 'card', 'is', 'Visa', 'Electron']),\n",
       "       list(['Off', 'to', 'the', 'bank', 'to', 'get', 'my', 'new', 'visa', 'platinum', 'card']),\n",
       "       list(['dearest', ',', 'you', 'rich', 'bastards', 'the', 'VISA', 'card', 'you', 'sent', 'me', \"doesn't\", 'work', 'why', 'screw', 'a', 'little', 'guy', 'like', 'me']),\n",
       "       list(['has', 'a', 'date', 'with', 'bobby', 'flay', 'and', 'gut', 'fieri', 'from', 'food', 'network']),\n",
       "       list(['Excited', 'about', 'seeing', 'Bobby', 'Flay', 'and', 'Guy', 'Fieri', 'tomorrow', 'at', 'the', 'Great', 'American', 'Food', '&amp', 'Music', 'Fest']),\n",
       "       list(['Gonna', 'go', 'see', 'Bobby', 'Flay', '2moro', 'at', 'Shoreline', 'Eat', 'and', 'drink', 'Gonna', 'be', 'good']),\n",
       "       list([\"can't\", 'wait', 'for', 'the', 'great', 'american', 'food', 'and', 'music', 'festival', 'at', 'shoreline', 'tomorrow', 'mmm', 'katz', 'pastrami', 'and', 'bobby', 'flay', 'yes', 'please']),\n",
       "       list(['My', 'dad', 'was', 'in', 'NY', 'for', 'a', 'day', 'we', 'ate', 'at', 'MESA', 'grill', 'last', 'night', 'and', 'met', 'Bobby', 'Flay', 'So', 'much', 'fun', 'except', 'I', 'completely', 'lost', 'my', 'voice', 'today']),\n",
       "       list(['Fighting', 'with', 'LaTex', 'Again']),\n",
       "       list(['we', 'love', 'you', 'too', 'and', \"don't\", 'want', 'you', 'to', 'die', 'Latex', '=', 'the', 'devil']),\n",
       "       list(['7', 'hours', '7', 'hours', 'of', 'inkscape', 'crashing', 'normally', 'solid', 'as', 'a', 'rock', '7', 'hours', 'of', 'LaTeX', 'complaining', 'at', 'the', 'slightest', 'thing', 'I', \"can't\", 'take', 'any', 'more']),\n",
       "       list(['How', 'to', 'Track', 'Iran', 'with', 'Social', 'Media']),\n",
       "       list([\"Shit's\", 'hitting', 'the', 'fan', 'in', 'Iran', 'craziness', 'indeed', 'iranelection']),\n",
       "       list(['Monday', 'already', 'Iran', 'may', 'implode', 'Kitchen', 'is', 'a', 'disaster', 'seems', 'happy', 'had', 'a', 'nice', 'weekend', 'and', 'is', 'great', 'whoop']),\n",
       "       list(['Twitter', 'Stock', 'buzz', 'AAPL', 'ES_F', 'SPY', 'SPX', 'PALM', 'updated', '12:00', 'PM']),\n",
       "       list(['getting', 'ready', 'to', 'test', 'out', 'some', 'burger', 'receipes', 'this', 'weekend', 'Bobby', 'Flay', 'has', 'some', 'great', 'receipes', 'to', 'try', 'Thanks', 'Bobby']),\n",
       "       list(['is', 'Bobby', 'Flay', 'joining', 'you']),\n",
       "       list(['i', 'lam', 'so', 'in', 'love', 'with', 'Bobby', 'Flay', 'he', 'is', 'my', 'favorite', 'RT', ':', 'you', 'need', 'a', 'place', 'in', 'Phoenix', 'We', 'have', 'great', 'peppers', 'here']),\n",
       "       list(['I', 'just', 'created', 'my', 'first', 'LaTeX', 'file', 'from', 'scratch', 'That', \"didn't\", 'work', 'out', 'very', 'well', 'See', ',', \"it's\", 'a', 'great', 'time', 'waster']),\n",
       "       list(['using', 'Linux', 'and', 'loving', 'it', '-', 'so', 'much', 'nicer', 'than', 'windows', 'Looking', 'forward', 'to', 'using', 'the', 'wysiwyg', 'latex', 'editor']),\n",
       "       list(['After', 'using', 'LaTeX', 'a', 'lot', 'any', 'other', 'typeset', 'mathematics', 'just', 'looks', 'hideous']),\n",
       "       list(['Ask', 'Programming', 'LaTeX', 'or', 'InDesign', 'submitted', 'by', 'calcio1', 'link', '[1', 'comment']),\n",
       "       list(['On', 'that', 'note', 'I', 'hate', 'Word', 'I', 'hate', 'Pages', 'I', 'hate', 'LaTeX', 'There', 'I', 'said', 'it', 'I', 'hate', 'LaTeX', 'All', 'you', 'TEXN3RDS', 'can', 'come', 'kill', 'me', 'now']),\n",
       "       list(['Ahhh', 'back', 'in', 'a', 'real', 'text', 'editing', 'environment', 'I', '&lt;3', 'LaTeX']),\n",
       "       list(['Trouble', 'in', 'Iran', 'I', 'see', 'Hmm', 'Iran', 'Iran', 'so', 'far', 'away', 'flockofseagullsweregeopoliticallycorrect']),\n",
       "       list(['Reading', 'the', 'tweets', 'coming', 'out', 'of', 'Iran', 'The', 'whole', 'thing', 'is', 'terrifying', 'and', 'incredibly', 'sad'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>[I, loooooooovvvvvveee, my, Kindle2, Not, that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>[Reading, my, kindle2, Love, it, Lee, childs, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>[Ok, first, assesment, of, the, kindle2, it, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>[You'll, love, your, Kindle2, I've, had, mine,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>[Fair, enough, But, i, have, the, Kindle2, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Mon May 11 03:22:00 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>GeorgeVHulme</td>\n",
       "      <td>[no, it, is, too, big, I'm, quite, happy, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Mon May 11 03:22:30 UTC 2009</td>\n",
       "      <td>aig</td>\n",
       "      <td>Seth937</td>\n",
       "      <td>[Fuck, this, economy, I, hate, aig, and, their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>Mon May 11 03:26:10 UTC 2009</td>\n",
       "      <td>jquery</td>\n",
       "      <td>dcostalis</td>\n",
       "      <td>[Jquery, is, my, new, best, friend]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>Mon May 11 03:27:15 UTC 2009</td>\n",
       "      <td>twitter</td>\n",
       "      <td>PJ_King</td>\n",
       "      <td>[Loves, twitter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>Mon May 11 03:29:20 UTC 2009</td>\n",
       "      <td>obama</td>\n",
       "      <td>mandanicole</td>\n",
       "      <td>[how, can, you, not, love, Obama, he, makes, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>Mon May 11 03:32:42 UTC 2009</td>\n",
       "      <td>obama</td>\n",
       "      <td>jpeb</td>\n",
       "      <td>[Check, this, video, out, --, President, Obama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>Mon May 11 03:32:48 UTC 2009</td>\n",
       "      <td>obama</td>\n",
       "      <td>kylesellers</td>\n",
       "      <td>[I, firmly, believe, that, Obama/Pelosi, have,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>Mon May 11 03:33:38 UTC 2009</td>\n",
       "      <td>obama</td>\n",
       "      <td>theviewfans</td>\n",
       "      <td>[House, Correspondents, dinner, was, last, nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>Mon May 11 05:05:58 UTC 2009</td>\n",
       "      <td>nike</td>\n",
       "      <td>MumsFP</td>\n",
       "      <td>[Watchin, Espn, Jus, seen, this, new, Nike, Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Mon May 11 05:06:22 UTC 2009</td>\n",
       "      <td>nike</td>\n",
       "      <td>vincentx24x</td>\n",
       "      <td>[dear, nike, stop, with, the, flywire, that, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>Mon May 11 05:20:15 UTC 2009</td>\n",
       "      <td>lebron</td>\n",
       "      <td>cameronwylie</td>\n",
       "      <td>[lebron, best, athlete, of, our, generation, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>Mon May 11 05:20:28 UTC 2009</td>\n",
       "      <td>lebron</td>\n",
       "      <td>luv8242</td>\n",
       "      <td>[I, was, talking, to, this, guy, last, night, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>Mon May 11 05:21:04 UTC 2009</td>\n",
       "      <td>lebron</td>\n",
       "      <td>mtgillikin</td>\n",
       "      <td>[i, love, lebron]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>Mon May 11 05:21:37 UTC 2009</td>\n",
       "      <td>lebron</td>\n",
       "      <td>ursecretdezire</td>\n",
       "      <td>[Lebron, is, a, Beast, but, I'm, still, cheeri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>Mon May 11 05:21:45 UTC 2009</td>\n",
       "      <td>lebron</td>\n",
       "      <td>Native_01</td>\n",
       "      <td>[lebron, IS, THE, BOSS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>Mon May 11 05:22:03 UTC 2009</td>\n",
       "      <td>lebron</td>\n",
       "      <td>princezzcutz</td>\n",
       "      <td>[Lebron, is, a, hometown, hero, to, me, lol, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>Mon May 11 05:22:12 UTC 2009</td>\n",
       "      <td>lebron</td>\n",
       "      <td>peterlikewhat</td>\n",
       "      <td>[lebron, and, zydrunas, are, such, an, awesome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>Mon May 11 05:22:37 UTC 2009</td>\n",
       "      <td>lebron</td>\n",
       "      <td>emceet</td>\n",
       "      <td>[Lebron, is, a, beast, nobody, in, the, NBA, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>Mon May 11 06:02:24 UTC 2009</td>\n",
       "      <td>iphone app</td>\n",
       "      <td>CocoSavanna</td>\n",
       "      <td>[downloading, apps, for, my, iphone, So, much,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>Mon May 11 19:47:29 UTC 2009</td>\n",
       "      <td>visa</td>\n",
       "      <td>DreambigRadio</td>\n",
       "      <td>[good, news, just, had, a, call, from, the, Vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>Mon May 11 19:49:21 UTC 2009</td>\n",
       "      <td>fredwilson</td>\n",
       "      <td>andrewwatson</td>\n",
       "      <td>[-, awesome, come, back, from, via, )]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>Mon May 11 19:50:07 UTC 2009</td>\n",
       "      <td>fredwilson</td>\n",
       "      <td>fredwilson</td>\n",
       "      <td>[In, montreal, for, a, long, weekend, of, R&amp;am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>Thu May 14 02:58:07 UTC 2009</td>\n",
       "      <td>\"booz allen\"</td>\n",
       "      <td>JoeSchueller</td>\n",
       "      <td>[Booz, Allen, Hamilton, has, a, bad, ass, home...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>Thu May 14 02:58:23 UTC 2009</td>\n",
       "      <td>\"booz allen\"</td>\n",
       "      <td>scottabel</td>\n",
       "      <td>[MLUC09, Customer, Innovation, Award, Winner, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>Thu May 14 05:24:50 UTC 2009</td>\n",
       "      <td>40d</td>\n",
       "      <td>JustMe_D</td>\n",
       "      <td>[I, current, use, the, Nikon, D90, and, love, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0</td>\n",
       "      <td>2579</td>\n",
       "      <td>Tue Jun 09 05:53:40 UTC 2009</td>\n",
       "      <td>iphone app</td>\n",
       "      <td>Jesssssii</td>\n",
       "      <td>[Man, I, kinda, dislike, Apple, right, now, Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>4</td>\n",
       "      <td>7011</td>\n",
       "      <td>Wed Jun 10 04:03:37 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>jimhong</td>\n",
       "      <td>[I, have, a, Kindle2, &amp;amp, Sony, PRS-500, Lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>4</td>\n",
       "      <td>7012</td>\n",
       "      <td>Wed Jun 10 04:03:53 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>Ant_Ward</td>\n",
       "      <td>[The, Kindle2, seems, the, best, eReader, but,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>4</td>\n",
       "      <td>7015</td>\n",
       "      <td>Wed Jun 10 05:24:40 UTC 2009</td>\n",
       "      <td>google</td>\n",
       "      <td>popitlockit</td>\n",
       "      <td>[I, have, a, google, addiction, Thank, you, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>2</td>\n",
       "      <td>7055</td>\n",
       "      <td>Wed Jun 10 15:31:56 UTC 2009</td>\n",
       "      <td>visa card</td>\n",
       "      <td>FionaSarah</td>\n",
       "      <td>[gem, My, primary, debit, card, is, Visa, Elec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2</td>\n",
       "      <td>8051</td>\n",
       "      <td>Wed Jun 10 15:31:59 UTC 2009</td>\n",
       "      <td>visa card</td>\n",
       "      <td>MalloryRayne</td>\n",
       "      <td>[Off, to, the, bank, to, get, my, new, visa, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>8052</td>\n",
       "      <td>Wed Jun 10 15:32:06 UTC 2009</td>\n",
       "      <td>visa card</td>\n",
       "      <td>_abi_</td>\n",
       "      <td>[dearest, ,, you, rich, bastards, the, VISA, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2</td>\n",
       "      <td>13051</td>\n",
       "      <td>Sat Jun 13 16:23:31 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>sfkerropi6</td>\n",
       "      <td>[has, a, date, with, bobby, flay, and, gut, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>4</td>\n",
       "      <td>13052</td>\n",
       "      <td>Sat Jun 13 16:24:08 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>tessalau</td>\n",
       "      <td>[Excited, about, seeing, Bobby, Flay, and, Guy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>4</td>\n",
       "      <td>13053</td>\n",
       "      <td>Sat Jun 13 16:24:12 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>ZFilth</td>\n",
       "      <td>[Gonna, go, see, Bobby, Flay, 2moro, at, Shore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>4</td>\n",
       "      <td>13054</td>\n",
       "      <td>Sat Jun 13 16:24:25 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>annieblane</td>\n",
       "      <td>[can't, wait, for, the, great, american, food,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>4</td>\n",
       "      <td>13055</td>\n",
       "      <td>Sat Jun 13 16:24:34 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>LAURAcBRYAN</td>\n",
       "      <td>[My, dad, was, in, NY, for, a, day, we, ate, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0</td>\n",
       "      <td>13073</td>\n",
       "      <td>Sun Jun 14 04:35:33 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>NathanChalmers</td>\n",
       "      <td>[Fighting, with, LaTex, Again]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0</td>\n",
       "      <td>13074</td>\n",
       "      <td>Sun Jun 14 04:35:53 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>LoonyLongbottom</td>\n",
       "      <td>[we, love, you, too, and, don't, want, you, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0</td>\n",
       "      <td>13075</td>\n",
       "      <td>Sun Jun 14 04:36:07 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>QuadError</td>\n",
       "      <td>[7, hours, 7, hours, of, inkscape, crashing, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>2</td>\n",
       "      <td>13076</td>\n",
       "      <td>Sun Jun 14 21:35:58 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>musicmuse</td>\n",
       "      <td>[How, to, Track, Iran, with, Social, Media]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0</td>\n",
       "      <td>13077</td>\n",
       "      <td>Sun Jun 14 21:36:04 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>sketoaks</td>\n",
       "      <td>[Shit's, hitting, the, fan, in, Iran, crazines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>13078</td>\n",
       "      <td>Sun Jun 14 21:36:09 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>jamespenycate</td>\n",
       "      <td>[Monday, already, Iran, may, implode, Kitchen,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2</td>\n",
       "      <td>14045</td>\n",
       "      <td>Sat Jun 13 16:13:59 UTC 2009</td>\n",
       "      <td>aapl</td>\n",
       "      <td>boardcentral</td>\n",
       "      <td>[Twitter, Stock, buzz, AAPL, ES_F, SPY, SPX, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>4</td>\n",
       "      <td>14046</td>\n",
       "      <td>Sat Jun 13 16:23:41 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>JimFacey</td>\n",
       "      <td>[getting, ready, to, test, out, some, burger, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>2</td>\n",
       "      <td>14049</td>\n",
       "      <td>Sat Jun 13 16:24:03 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>wetfishdesigns</td>\n",
       "      <td>[is, Bobby, Flay, joining, you]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>4</td>\n",
       "      <td>14050</td>\n",
       "      <td>Sat Jun 13 16:24:15 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>A_TALL_BLONDE</td>\n",
       "      <td>[i, lam, so, in, love, with, Bobby, Flay, he, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0</td>\n",
       "      <td>14069</td>\n",
       "      <td>Sun Jun 14 04:31:12 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>rooney_tunes</td>\n",
       "      <td>[I, just, created, my, first, LaTeX, file, fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>4</td>\n",
       "      <td>14070</td>\n",
       "      <td>Sun Jun 14 04:31:23 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>roguemovement</td>\n",
       "      <td>[using, Linux, and, loving, it, -, so, much, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>4</td>\n",
       "      <td>14071</td>\n",
       "      <td>Sun Jun 14 04:31:28 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>yomcat</td>\n",
       "      <td>[After, using, LaTeX, a, lot, any, other, type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2</td>\n",
       "      <td>14072</td>\n",
       "      <td>Sun Jun 14 04:31:43 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>proggit</td>\n",
       "      <td>[Ask, Programming, LaTeX, or, InDesign, submit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0</td>\n",
       "      <td>14073</td>\n",
       "      <td>Sun Jun 14 04:32:17 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>sam33r</td>\n",
       "      <td>[On, that, note, I, hate, Word, I, hate, Pages...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4</td>\n",
       "      <td>14074</td>\n",
       "      <td>Sun Jun 14 04:36:34 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>iamtheonlyjosie</td>\n",
       "      <td>[Ahhh, back, in, a, real, text, editing, envir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>14075</td>\n",
       "      <td>Sun Jun 14 21:36:07 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>plutopup7</td>\n",
       "      <td>[Trouble, in, Iran, I, see, Hmm, Iran, Iran, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>14076</td>\n",
       "      <td>Sun Jun 14 21:36:17 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>captain_pete</td>\n",
       "      <td>[Reading, the, tweets, coming, out, of, Iran, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     polarity     id                          date         query  \\\n",
       "0           4      3  Mon May 11 03:17:40 UTC 2009       kindle2   \n",
       "1           4      4  Mon May 11 03:18:03 UTC 2009       kindle2   \n",
       "2           4      5  Mon May 11 03:18:54 UTC 2009       kindle2   \n",
       "3           4      6  Mon May 11 03:19:04 UTC 2009       kindle2   \n",
       "4           4      7  Mon May 11 03:21:41 UTC 2009       kindle2   \n",
       "5           4      8  Mon May 11 03:22:00 UTC 2009       kindle2   \n",
       "6           0      9  Mon May 11 03:22:30 UTC 2009           aig   \n",
       "7           4     10  Mon May 11 03:26:10 UTC 2009        jquery   \n",
       "8           4     11  Mon May 11 03:27:15 UTC 2009       twitter   \n",
       "9           4     12  Mon May 11 03:29:20 UTC 2009         obama   \n",
       "10          2     13  Mon May 11 03:32:42 UTC 2009         obama   \n",
       "11          0     14  Mon May 11 03:32:48 UTC 2009         obama   \n",
       "12          4     15  Mon May 11 03:33:38 UTC 2009         obama   \n",
       "13          4     16  Mon May 11 05:05:58 UTC 2009          nike   \n",
       "14          0     17  Mon May 11 05:06:22 UTC 2009          nike   \n",
       "15          4     18  Mon May 11 05:20:15 UTC 2009        lebron   \n",
       "16          0     19  Mon May 11 05:20:28 UTC 2009        lebron   \n",
       "17          4     20  Mon May 11 05:21:04 UTC 2009        lebron   \n",
       "18          0     21  Mon May 11 05:21:37 UTC 2009        lebron   \n",
       "19          4     22  Mon May 11 05:21:45 UTC 2009        lebron   \n",
       "20          4     23  Mon May 11 05:22:03 UTC 2009        lebron   \n",
       "21          4     24  Mon May 11 05:22:12 UTC 2009        lebron   \n",
       "22          4     25  Mon May 11 05:22:37 UTC 2009        lebron   \n",
       "23          4     26  Mon May 11 06:02:24 UTC 2009    iphone app   \n",
       "24          4     33  Mon May 11 19:47:29 UTC 2009          visa   \n",
       "25          4     34  Mon May 11 19:49:21 UTC 2009    fredwilson   \n",
       "26          4     35  Mon May 11 19:50:07 UTC 2009    fredwilson   \n",
       "27          4     46  Thu May 14 02:58:07 UTC 2009  \"booz allen\"   \n",
       "28          4     47  Thu May 14 02:58:23 UTC 2009  \"booz allen\"   \n",
       "29          4     49  Thu May 14 05:24:50 UTC 2009           40d   \n",
       "..        ...    ...                           ...           ...   \n",
       "468         0   2579  Tue Jun 09 05:53:40 UTC 2009    iphone app   \n",
       "469         4   7011  Wed Jun 10 04:03:37 UTC 2009       kindle2   \n",
       "470         4   7012  Wed Jun 10 04:03:53 UTC 2009       kindle2   \n",
       "471         4   7015  Wed Jun 10 05:24:40 UTC 2009        google   \n",
       "472         2   7055  Wed Jun 10 15:31:56 UTC 2009     visa card   \n",
       "473         2   8051  Wed Jun 10 15:31:59 UTC 2009     visa card   \n",
       "474         0   8052  Wed Jun 10 15:32:06 UTC 2009     visa card   \n",
       "475         2  13051  Sat Jun 13 16:23:31 UTC 2009    Bobby Flay   \n",
       "476         4  13052  Sat Jun 13 16:24:08 UTC 2009    Bobby Flay   \n",
       "477         4  13053  Sat Jun 13 16:24:12 UTC 2009    Bobby Flay   \n",
       "478         4  13054  Sat Jun 13 16:24:25 UTC 2009    Bobby Flay   \n",
       "479         4  13055  Sat Jun 13 16:24:34 UTC 2009    Bobby Flay   \n",
       "480         0  13073  Sun Jun 14 04:35:33 UTC 2009         latex   \n",
       "481         0  13074  Sun Jun 14 04:35:53 UTC 2009         latex   \n",
       "482         0  13075  Sun Jun 14 04:36:07 UTC 2009         latex   \n",
       "483         2  13076  Sun Jun 14 21:35:58 UTC 2009          iran   \n",
       "484         0  13077  Sun Jun 14 21:36:04 UTC 2009          iran   \n",
       "485         0  13078  Sun Jun 14 21:36:09 UTC 2009          iran   \n",
       "486         2  14045  Sat Jun 13 16:13:59 UTC 2009          aapl   \n",
       "487         4  14046  Sat Jun 13 16:23:41 UTC 2009    Bobby Flay   \n",
       "488         2  14049  Sat Jun 13 16:24:03 UTC 2009    Bobby Flay   \n",
       "489         4  14050  Sat Jun 13 16:24:15 UTC 2009    Bobby Flay   \n",
       "490         0  14069  Sun Jun 14 04:31:12 UTC 2009         latex   \n",
       "491         4  14070  Sun Jun 14 04:31:23 UTC 2009         latex   \n",
       "492         4  14071  Sun Jun 14 04:31:28 UTC 2009         latex   \n",
       "493         2  14072  Sun Jun 14 04:31:43 UTC 2009         latex   \n",
       "494         0  14073  Sun Jun 14 04:32:17 UTC 2009         latex   \n",
       "495         4  14074  Sun Jun 14 04:36:34 UTC 2009         latex   \n",
       "496         0  14075  Sun Jun 14 21:36:07 UTC 2009          iran   \n",
       "497         0  14076  Sun Jun 14 21:36:17 UTC 2009          iran   \n",
       "\n",
       "                user                                              tweet  \n",
       "0             tpryan  [I, loooooooovvvvvveee, my, Kindle2, Not, that...  \n",
       "1             vcu451  [Reading, my, kindle2, Love, it, Lee, childs, ...  \n",
       "2             chadfu  [Ok, first, assesment, of, the, kindle2, it, f...  \n",
       "3              SIX15  [You'll, love, your, Kindle2, I've, had, mine,...  \n",
       "4           yamarama  [Fair, enough, But, i, have, the, Kindle2, and...  \n",
       "5       GeorgeVHulme  [no, it, is, too, big, I'm, quite, happy, with...  \n",
       "6            Seth937  [Fuck, this, economy, I, hate, aig, and, their...  \n",
       "7          dcostalis                [Jquery, is, my, new, best, friend]  \n",
       "8            PJ_King                                   [Loves, twitter]  \n",
       "9        mandanicole  [how, can, you, not, love, Obama, he, makes, j...  \n",
       "10              jpeb  [Check, this, video, out, --, President, Obama...  \n",
       "11       kylesellers  [I, firmly, believe, that, Obama/Pelosi, have,...  \n",
       "12       theviewfans  [House, Correspondents, dinner, was, last, nig...  \n",
       "13            MumsFP  [Watchin, Espn, Jus, seen, this, new, Nike, Co...  \n",
       "14       vincentx24x  [dear, nike, stop, with, the, flywire, that, s...  \n",
       "15      cameronwylie  [lebron, best, athlete, of, our, generation, i...  \n",
       "16           luv8242  [I, was, talking, to, this, guy, last, night, ...  \n",
       "17        mtgillikin                                  [i, love, lebron]  \n",
       "18    ursecretdezire  [Lebron, is, a, Beast, but, I'm, still, cheeri...  \n",
       "19         Native_01                            [lebron, IS, THE, BOSS]  \n",
       "20      princezzcutz  [Lebron, is, a, hometown, hero, to, me, lol, I...  \n",
       "21     peterlikewhat  [lebron, and, zydrunas, are, such, an, awesome...  \n",
       "22            emceet  [Lebron, is, a, beast, nobody, in, the, NBA, c...  \n",
       "23       CocoSavanna  [downloading, apps, for, my, iphone, So, much,...  \n",
       "24     DreambigRadio  [good, news, just, had, a, call, from, the, Vi...  \n",
       "25      andrewwatson             [-, awesome, come, back, from, via, )]  \n",
       "26        fredwilson  [In, montreal, for, a, long, weekend, of, R&am...  \n",
       "27      JoeSchueller  [Booz, Allen, Hamilton, has, a, bad, ass, home...  \n",
       "28         scottabel  [MLUC09, Customer, Innovation, Award, Winner, ...  \n",
       "29          JustMe_D  [I, current, use, the, Nikon, D90, and, love, ...  \n",
       "..               ...                                                ...  \n",
       "468        Jesssssii  [Man, I, kinda, dislike, Apple, right, now, Ca...  \n",
       "469          jimhong  [I, have, a, Kindle2, &amp, Sony, PRS-500, Lik...  \n",
       "470         Ant_Ward  [The, Kindle2, seems, the, best, eReader, but,...  \n",
       "471      popitlockit  [I, have, a, google, addiction, Thank, you, fo...  \n",
       "472       FionaSarah  [gem, My, primary, debit, card, is, Visa, Elec...  \n",
       "473     MalloryRayne  [Off, to, the, bank, to, get, my, new, visa, p...  \n",
       "474            _abi_  [dearest, ,, you, rich, bastards, the, VISA, c...  \n",
       "475       sfkerropi6  [has, a, date, with, bobby, flay, and, gut, fi...  \n",
       "476         tessalau  [Excited, about, seeing, Bobby, Flay, and, Guy...  \n",
       "477           ZFilth  [Gonna, go, see, Bobby, Flay, 2moro, at, Shore...  \n",
       "478       annieblane  [can't, wait, for, the, great, american, food,...  \n",
       "479      LAURAcBRYAN  [My, dad, was, in, NY, for, a, day, we, ate, a...  \n",
       "480   NathanChalmers                     [Fighting, with, LaTex, Again]  \n",
       "481  LoonyLongbottom  [we, love, you, too, and, don't, want, you, to...  \n",
       "482        QuadError  [7, hours, 7, hours, of, inkscape, crashing, n...  \n",
       "483        musicmuse        [How, to, Track, Iran, with, Social, Media]  \n",
       "484         sketoaks  [Shit's, hitting, the, fan, in, Iran, crazines...  \n",
       "485    jamespenycate  [Monday, already, Iran, may, implode, Kitchen,...  \n",
       "486     boardcentral  [Twitter, Stock, buzz, AAPL, ES_F, SPY, SPX, P...  \n",
       "487         JimFacey  [getting, ready, to, test, out, some, burger, ...  \n",
       "488   wetfishdesigns                    [is, Bobby, Flay, joining, you]  \n",
       "489    A_TALL_BLONDE  [i, lam, so, in, love, with, Bobby, Flay, he, ...  \n",
       "490     rooney_tunes  [I, just, created, my, first, LaTeX, file, fro...  \n",
       "491    roguemovement  [using, Linux, and, loving, it, -, so, much, n...  \n",
       "492           yomcat  [After, using, LaTeX, a, lot, any, other, type...  \n",
       "493          proggit  [Ask, Programming, LaTeX, or, InDesign, submit...  \n",
       "494           sam33r  [On, that, note, I, hate, Word, I, hate, Pages...  \n",
       "495  iamtheonlyjosie  [Ahhh, back, in, a, real, text, editing, envir...  \n",
       "496        plutopup7  [Trouble, in, Iran, I, see, Hmm, Iran, Iran, s...  \n",
       "497     captain_pete  [Reading, the, tweets, coming, out, of, Iran, ...  \n",
       "\n",
       "[498 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load slang table\n",
    "path = \"./Lexiques/SlangLookupTable.txt\"\n",
    "dict_slang = {}\n",
    "with open(path, 'rb') as f:\n",
    "    contents = f.read()\n",
    "    contents = contents.decode(\"latin1\")\n",
    "    contents = contents.split(\"\\n\")\n",
    "contents.pop(len(contents) - 1)\n",
    "for row in contents:\n",
    "    row_list = row.split('\\t')\n",
    "    row_list[1] = re.sub('\\xa0', '', row_list[1])\n",
    "    row_list[1] = re.sub('\\r', '', row_list[1])\n",
    "    dict_slang[row_list[0]] = row_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etiquetage grammatical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taggedData = []\n",
    "for i in df['tweet']:\n",
    "    taggedData.append(nltk.pos_tag(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('House', 'NNP'),\n",
       " ('Correspondents', 'NNP'),\n",
       " ('dinner', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('last', 'JJ'),\n",
       " ('night', 'NN'),\n",
       " ('whoopi', 'NN'),\n",
       " ('barbara', 'NN'),\n",
       " ('&amp', 'NNP'),\n",
       " ('sherri', 'NN'),\n",
       " ('went', 'VBD'),\n",
       " ('Obama', 'NNP'),\n",
       " ('got', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('standing', 'NN'),\n",
       " ('ovation', 'NN')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taggedData[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adjectif_tags = ['JJ','JJR','JJS']\n",
    "noun_tags = ['NN','NNP','NNPS','NNS']\n",
    "adverb_tags = ['RB','RBR','RBS']\n",
    "verb_tags = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 1027 verbes dans le corpus de tweets\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "cpt = 0\n",
    "\n",
    "for list in taggedData:\n",
    "    for tag in list:\n",
    "        if(tag[1] in verb_tags):\n",
    "            cpt+=1\n",
    "        else:\n",
    "            i+=1\n",
    "print('Il y a', cpt, 'verbes dans le corpus de tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithme de d√©tection v1 : appel au dictionnaire Sentiwordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breakdown.n.03\tPosScore: 0.0\tNegScore: 0.25\n"
     ]
    }
   ],
   "source": [
    "swn_filename = './Lexiques/SentiWordNet_3.0.0_20100705.txt'\n",
    "swn = SentiWordNetCorpusReader(swn_filename)\n",
    "print(swn.senti_synset('breakdown.n.03'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_tweet = []\n",
    "\n",
    "for tags in taggedData:\n",
    "    new_tweet = []\n",
    "    for tag in tags:\n",
    "        if tag[1] in verb_tags or tag[1] in noun_tags or tag[1] in adverb_tags or tag[1] in adjectif_tags:\n",
    "            new_tweet.append(tag)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    list_tweet.append(new_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"You'll\", 'NNP'),\n",
       " ('love', 'VB'),\n",
       " ('Kindle2', 'NNP'),\n",
       " (\"I've\", 'NNP'),\n",
       " ('had', 'VBD'),\n",
       " ('mine', 'NN'),\n",
       " ('few', 'JJ'),\n",
       " ('months', 'NNS'),\n",
       " ('never', 'RB'),\n",
       " ('looked', 'VBD'),\n",
       " ('new', 'JJ'),\n",
       " ('big', 'JJ'),\n",
       " ('one', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('huge', 'JJ'),\n",
       " ('No', 'NNP'),\n",
       " ('need', 'NN'),\n",
       " ('remorse', 'NN'),\n",
       " (':)', 'NN')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tweet[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synset_v1 = []\n",
    "for tweets in list_tweet:\n",
    "    score_pos = 0\n",
    "    score_neg = 0\n",
    "    sentiment = []\n",
    "\n",
    "    for tweet in tweets:\n",
    "        sentiment.append(tweet)\n",
    "        mot = tweet[0]\n",
    "        mot = wn.synsets(mot)\n",
    "        if(mot != []):\n",
    "            mot = mot[0].name()\n",
    "            mot = swn.senti_synset(mot)\n",
    "            if(mot!= None):\n",
    "                score_pos += mot.pos_score\n",
    "                score_neg += mot.neg_score\n",
    "    sentiment.append(score_pos)\n",
    "    sentiment.append(score_neg)\n",
    "    if(score_neg > score_pos):\n",
    "        sentiment.append(0)\n",
    "    elif(score_neg == score_pos):\n",
    "        sentiment.append(2)\n",
    "    else:\n",
    "        sentiment.append(4)\n",
    "    \n",
    "    synset_v1.append(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation de la V1\n",
      "recall :  0.4961101709059275\n",
      "precision :  0.5201023391812866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 71,  32,  74],\n",
       "       [ 14,  61,  64],\n",
       "       [ 29,  35, 118]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_v1 = []\n",
    "for i, scores in enumerate(synset_v1):\n",
    "    scores_v1.append(synset_v1[i][-1:][0])\n",
    "scores_v1 = pd.DataFrame(scores_v1, columns=['y_pred'])\n",
    "y_true = df['polarity']\n",
    "y_pred = scores_v1['y_pred']\n",
    "\n",
    "print('Evaluation de la V1')\n",
    "\n",
    "recall = recall_score(y_true, y_pred, average='macro') \n",
    "print(\"recall : \", recall)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='macro') \n",
    "print(\"precision : \", precision)\n",
    "\n",
    "\n",
    "frames = [y_pred, y_true]\n",
    "result = pd.concat(frames, axis=1)\n",
    "\n",
    "confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet positifs correctement pr√©dits :\n"
     ]
    }
   ],
   "source": [
    "tw = np.where( (result['y_pred'] == 4 ) & (result['polarity'] == 4 ))\n",
    "print('Tweet positifs correctement pr√©dits :')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 tweets ont √©t√© correctement pr√©dits\n"
     ]
    }
   ],
   "source": [
    "res = result[\"y_pred\"] == result[\"polarity\"]\n",
    "cpt = 0\n",
    "for i in res:\n",
    "    if(i is True):\n",
    "        cpt+=1 \n",
    "    else:\n",
    "        pass\n",
    "print(cpt, 'tweets ont √©t√© correctement pr√©dits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithme de d√©tection v2 : gestion de la n√©gation et des modifieurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"./Lexiques/NegatingWordList.txt\"\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    contents = f.read()\n",
    "    contents = contents.decode(\"latin1\")\n",
    "    contents = contents.split(\"\\n\")\n",
    "contents.pop(len(contents) - 1)\n",
    "negative_w = contents\n",
    "\n",
    "path = \"./Lexiques/BoosterWordList.txt\"\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    contents = f.read()\n",
    "    contents = contents.decode(\"latin1\")\n",
    "    contents = contents.split(\"\\n\")\n",
    "contents.pop(len(contents) - 1)\n",
    "booster_w = contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synset_v2 = []\n",
    "for tweets in list_tweet:\n",
    "    score_pos = 0\n",
    "    score_neg = 0\n",
    "    sentiment = []\n",
    "\n",
    "    for j, tweet in enumerate(tweets):\n",
    "        sentiment.append(tweet)\n",
    "        mot = tweet[0]\n",
    "        mot = wn.synsets(mot)\n",
    "        if(mot != []):\n",
    "            mot = mot[0].name()\n",
    "            mot = swn.senti_synset(mot)\n",
    "            if(mot != None):\n",
    "                if (j >= 1):\n",
    "                    if(tweets[j-1][0].lower() in negative_w):\n",
    "                        score_pos += mot.neg_score\n",
    "                        score_neg += mot.pos_score\n",
    "                        \n",
    "                    elif(tweets[j-1][0].lower() in booster_w):\n",
    "                        score_pos += mot.pos_score * 2\n",
    "                        score_neg += mot.neg_score * 2\n",
    "                    else:\n",
    "                        score_pos += mot.pos_score\n",
    "                        score_neg += mot.neg_score\n",
    "                else:\n",
    "                    score_pos += mot.pos_score\n",
    "                    score_neg += mot.neg_score\n",
    "\n",
    "    sentiment.append(score_pos)\n",
    "    sentiment.append(score_neg)\n",
    "    if(score_neg > score_pos):\n",
    "        sentiment.append(0)\n",
    "    elif(score_neg == score_pos):\n",
    "        sentiment.append(2)\n",
    "    else:\n",
    "        sentiment.append(4)\n",
    "\n",
    "    synset_v2.append(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation de la V2\n",
      "recall :  0.5036431275914266\n",
      "precision :  0.5280957111999418\n",
      "254 tweets ont √©t√© correctement pr√©dits\n"
     ]
    }
   ],
   "source": [
    "scores_v2 = []\n",
    "for i, scores in enumerate(synset_v2):\n",
    "    scores_v2.append(synset_v2[i][-1:][0])\n",
    "scores_v2 = pd.DataFrame(scores_v2, columns=['y_pred'])\n",
    "y_true = df['polarity']\n",
    "y_pred = scores_v2['y_pred']\n",
    "\n",
    "confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "print('Evaluation de la V2')\n",
    "\n",
    "recall = recall_score(y_true, y_pred, average='macro') \n",
    "print(\"recall : \", recall)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='macro') \n",
    "print(\"precision : \", precision)\n",
    "\n",
    "\n",
    "frames = [y_pred, y_true]\n",
    "result = pd.concat(frames, axis=1)\n",
    "\n",
    "confusion_matrix(y_true, y_pred)\n",
    "\n",
    "res = result[\"y_pred\"] == result[\"polarity\"]\n",
    "cpt = 0\n",
    "for i in res:\n",
    "    if(i is True):\n",
    "        cpt+=1 \n",
    "    else:\n",
    "        pass\n",
    "print(cpt, 'tweets ont √©t√© correctement pr√©dits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smileys = {}\n",
    "smileys_pos = []\n",
    "smileys_neg = []\n",
    "\n",
    "with open('Lexiques/EmoticonLookupTable.txt', 'rb') as f:\n",
    "    contents = f.read()\n",
    "    contents = contents.decode(\"latin1\")\n",
    "    contents = contents.split('\\n')\n",
    "for c in contents:\n",
    "    c = c.split('\\t')\n",
    "    if c[0] != \"\":\n",
    "        smileys[c[0]] = c[1]\n",
    "for smiley in smileys.items():\n",
    "    if (smiley[1] == '-1'):\n",
    "        smileys_neg.append(smiley[0])\n",
    "    elif (smiley[1] == '1'):\n",
    "        smileys_pos.append(smiley[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithme de d√©tection v3 : gestion des emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synset_v3 = []\n",
    "for tweets in list_tweet:\n",
    "    score_pos = 0\n",
    "    score_neg = 0\n",
    "    sentiment = []\n",
    "\n",
    "    for j, tweet in enumerate(tweets):\n",
    "        sentiment.append(tweet)\n",
    "        if(tweet[0] in smileys_neg):\n",
    "            score_neg += 1\n",
    "        if(tweet[0] in smileys_pos):\n",
    "            score_pos += 1\n",
    "        mot = tweet[0]\n",
    "        mot = wn.synsets(mot)\n",
    "        if(mot != []):\n",
    "            mot = mot[0].name()\n",
    "            mot = swn.senti_synset(mot)\n",
    "            if(mot != None):\n",
    "                if (j >= 1):\n",
    "                    if(tweets[j-1][0].lower() in negative_w):\n",
    "                        score_pos += mot.neg_score\n",
    "                        score_neg += mot.pos_score\n",
    "                        \n",
    "                    elif(tweets[j-1][0].lower() in booster_w):\n",
    "                        score_pos += mot.pos_score * 2\n",
    "                        score_neg += mot.neg_score * 2\n",
    "                    else:\n",
    "                        score_pos += mot.pos_score\n",
    "                        score_neg += mot.neg_score\n",
    "                else:\n",
    "                    score_pos += mot.pos_score\n",
    "                    score_neg += mot.neg_score\n",
    "\n",
    "    sentiment.append(score_pos)\n",
    "    sentiment.append(score_neg)\n",
    "    if(score_neg > score_pos):\n",
    "        sentiment.append(0)\n",
    "    elif(score_neg == score_pos):\n",
    "        sentiment.append(2)\n",
    "    else:\n",
    "        sentiment.append(4)\n",
    "\n",
    "    synset_v3.append(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation de la V3\n",
      "recall :  0.5315812911228105\n",
      "precision :  0.5556878306878307\n",
      "269 tweets ont √©t√© correctement pr√©dits\n"
     ]
    }
   ],
   "source": [
    "scores_v3 = []\n",
    "for i, scores in enumerate(synset_v3):\n",
    "    scores_v3.append(synset_v3[i][-1:][0])\n",
    "scores_v3 = pd.DataFrame(scores_v3, columns=['y_pred'])\n",
    "y_true = df['polarity']\n",
    "y_pred = scores_v3['y_pred']\n",
    "\n",
    "confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "print('Evaluation de la V3')\n",
    "\n",
    "recall = recall_score(y_true, y_pred, average='macro') \n",
    "print(\"recall : \", recall)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='macro') \n",
    "print(\"precision : \", precision)\n",
    "\n",
    "\n",
    "\n",
    "frames = [y_pred, y_true]\n",
    "result = pd.concat(frames, axis=1)\n",
    "\n",
    "confusion_matrix(y_true, y_pred)\n",
    "\n",
    "res = result[\"y_pred\"] == result[\"polarity\"]\n",
    "cpt = 0\n",
    "for i in res:\n",
    "    if(i is True):\n",
    "        cpt+=1 \n",
    "    else:\n",
    "        pass\n",
    "print(cpt, 'tweets ont √©t√© correctement pr√©dits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('not', 'RB'),\n",
       " ('love', 'VB'),\n",
       " ('Obama', 'NNP'),\n",
       " ('makes', 'VBZ'),\n",
       " ('jokes', 'NNS'),\n",
       " 1.5,\n",
       " 0.625,\n",
       " 4]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset_v1[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('not', 'RB'),\n",
       " ('love', 'VB'),\n",
       " ('Obama', 'NNP'),\n",
       " ('makes', 'VBZ'),\n",
       " ('jokes', 'NNS'),\n",
       " 0.875,\n",
       " 1.25,\n",
       " 0]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset_v2[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"You'll\", 'NNP'),\n",
       " ('love', 'VB'),\n",
       " ('Kindle2', 'NNP'),\n",
       " (\"I've\", 'NNP'),\n",
       " ('had', 'VBD'),\n",
       " ('mine', 'NN'),\n",
       " ('few', 'JJ'),\n",
       " ('months', 'NNS'),\n",
       " ('never', 'RB'),\n",
       " ('looked', 'VBD'),\n",
       " ('new', 'JJ'),\n",
       " ('big', 'JJ'),\n",
       " ('one', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('huge', 'JJ'),\n",
       " ('No', 'NNP'),\n",
       " ('need', 'NN'),\n",
       " ('remorse', 'NN'),\n",
       " (':)', 'NN'),\n",
       " 3.0,\n",
       " 1.875,\n",
       " 4]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset_v3[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
